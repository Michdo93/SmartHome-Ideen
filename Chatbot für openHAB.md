# Konzeption und Implementierung eines webbasierten Chatbots mit trainierbarem KI-Modul zur Interaktion mit openHAB

---

## ğŸ“ **TitelvorschlÃ¤ge fÃ¼r die Bachelorthesis**

1. **Entwicklung eines KI-gestÃ¼tzten Chatbots fÃ¼r Smart-Home-Steuerung mit Flask und selbsttrainierbarem Modell**
2. **Konzeption und Implementierung eines webbasierten Chatbots mit trainierbarem KI-Modul zur Interaktion mit openHAB**
3. **Webbasierte Benutzer- und AdminoberflÃ¤che fÃ¼r ein dynamisch lernfÃ¤higes Chatbot-System im Smart-Home-Kontext**
4. **Design und Umsetzung eines selbstlernenden Chatbots mit dynamischem Training Ã¼ber eine Admin-WeboberflÃ¤che**
5. **Architektur eines benutzerzentrierten KI-Systems zur Chat-basierten Steuerung von Smart Homes**
6. **Aufbau eines anpassbaren, KI-basierten Dialogsystems mit Flask und dynamischem Modelltraining fÃ¼r Smart Homes**
7. **Entwicklung eines KI-gestÃ¼tzten Chatbots mit dynamischem Training und Web-OberflÃ¤che zur Smart-Home-Interaktion**
8. ...

Der Titel der Thesis muss erst kurz vor Abgabe endgÃ¼ltig feststehen.

---

## ğŸ“£ **Ausschreibungstext fÃ¼r die Bachelorthesis**

### **Beschreibung:**

Im Rahmen dieser Bachelorarbeit soll ein interaktives Chatbot-System fÃ¼r die Steuerung von Smart-Home-GerÃ¤ten Ã¼ber **openHAB** entwickelt werden. Die Besonderheit: Das System soll nicht auf statisch definierten Regeln oder externen KI-Diensten (wie ChatGPT) basieren, sondern eine **eigenstÃ¤ndig trainierbare KI** verwenden, die Ã¼ber eine **WeboberflÃ¤che von Administratoren gepflegt und erweitert werden kann**.

---

### **Ziele der Arbeit:**

* Entwurf und Umsetzung einer **Flask-basierten Webanwendung** mit zwei Benutzerrollen: Nutzer (Chat) und Administrator (Training).
* Integration einer **KI-Komponente**, die auf Basis von Benutzereingaben trainiert werden kann.
* Implementierung einer **Datenbank** zur Speicherung von Trainingsdaten, ChatverlÃ¤ufen und Benutzerinformationen.
* Aufbau einer **Admin-OberflÃ¤che**, Ã¼ber die Intents, EntitÃ¤ten und Beispiele eingegeben werden kÃ¶nnen.
* Dynamische AuslÃ¶sung des Trainingsprozesses per Button in der WeboberflÃ¤che.
* Anbindung an openHAB Ã¼ber die REST API zur AusfÃ¼hrung realer Aktionen im Smart-Home-System.

---

### **Technologien & Tools:**

* **Programmiersprache**: Python
* **Frameworks**: Flask (Web), optional TensorFlow/Rasa/spaCy/Hugging Face (fÃ¼r die KI)
* **Datenbank**: SQLite oder MySQL
* **KI-Training**: Dynamisch Ã¼ber das Admin-Interface
* **API-Kommunikation**: openHAB REST API

---

### **Voraussetzungen:**

* Gute Kenntnisse in Python
* Erste Erfahrungen mit Webentwicklung (Flask, HTML/JS)
* Interesse an kÃ¼nstlicher Intelligenz und maschinellem Lernen
* SelbststÃ¤ndiges Arbeiten und kreative ProblemlÃ¶sung

---

### **Ergebnis der Arbeit:**

Ein **vollstÃ¤ndig funktionierender Prototyp** eines KI-gestÃ¼tzten, webbasierten Chatbot-Systems zur Steuerung eines Smart Homes. Die Arbeit kann spÃ¤ter erweitert und als Open-Source-Projekt verÃ¶ffentlicht werden.

---

## âœ… Vorteile der Trennung von Benutzer-Chat, Admin-Panel und zentraler API

### 1. **ModularitÃ¤t**

* **Frontend 1: Benutzer-Chat**

  * Eigene, schmale OberflÃ¤che nur fÃ¼r Endnutzer.
* **Frontend 2: Admin-Panel**

  * Separat, geschÃ¼tzt, mit anderen Funktionen (z.â€¯B. Datenpflege, Training).

â†’ Beide greifen auf dieselbe **zentralisierte API** zu.

---

### 2. **Zentrale Kommunikationsschnittstelle (API-Gateway)**

Ein zentrales Backend (Flask API) dient als Schnittstelle fÃ¼r alle Clients:

```
Clients:
- Benutzer-Chat (Web)
- Admin-Panel (Web)
- Sprachassistent (z.â€¯B. Alexa, Raspberry Pi, Android-App)
- Mobile App
â†’ alle Ã¼ber eine einheitliche REST-API
```

Diese API regelt:

* Authentifizierung (JWT, OAuth, etc.)
* Datenverwaltung (Trainingsdaten, Logs)
* Chat-Dispatch: Anfrage â†’ Modell â†’ Antwort
* Trigger fÃ¼r Modelltraining
* GerÃ¤te-Interaktion (Ã¼ber openHAB)

---

### 3. **Sprachassistent einfach integrierbar**

Dies wÃ¤re in einem weiteren Projekt (weitere Thesis umsetzbar).

Es gilt:

* Chat-Eingabe â†’ ersetzt durch **Speech-to-Text**
* Chat-Ausgabe â†’ ersetzt durch **Text-to-Speech**

Dazu braucht der Client (z.â€¯B. in Python oder als App):

* Mikrofon â†’ STT (z.â€¯B. Google Speech, Whisper)
* Text senden â†’ REST-API
* Antwort empfangen â†’ TTS (z.â€¯B. pyttsx3, gTTS, ElevenLabs) â†’ Lautsprecher

---

## ğŸ§± Empfehlung: Systemaufbau (logisch)

![picture alt](https://raw.githubusercontent.com/Michdo93/SmartHome-Ideen/refs/heads/main/screenshots/chatbot.png)

### Idee

Aufbau eines **KI-gestÃ¼tzten Chatbots mit einer Web-OberflÃ¤che** zur Verwaltung und **Training** in einem System wie **Flask**. Der Workflow wÃ¼rde sicherstellen, dass **Admins** das Modell trainieren kÃ¶nnen, ohne tief in den Code einzugreifen, sondern alles Ã¼ber eine BenutzeroberflÃ¤che (Admin-Dashboard) steuern. Auch das dynamische **Trainieren des Modells** basierend auf neuen Benutzereingaben ist eine spannende Herausforderung.

Warum dieses Vorgehen?

Ein Smart-Home-System wie openHAB wird immer wieder erweitert. Es kommen neue GerÃ¤te und somit Things hinzu, zudem es entsprechend immer wieder neuere Items gibt. Eventuell werden alte GerÃ¤te ausgetauscht und gar entfernt, was dazu fÃ¼hrt, dass man die dazugehÃ¶rigen Things und Items ebenfalls lÃ¶scht. FÃ¼r den Chatbot bedeutet dies, dass er natÃ¼rlich immer nur auf den aktuellen Stand des Smart-Homes reagieren soll. Ein Chatbot, welches Informationen von alten GerÃ¤ten ausgeben mÃ¶chte, wÃ¼rde zum einen nichts bringen und zum anderen vermutlich gar keien Informationen zurÃ¼ckliefern kÃ¶nnen. Ebenfalls wÃ¤re der Versuch GerÃ¤te zu steuern, die gar nicht vorhanden sind fatal. Ein neues GerÃ¤t, welches man steuern mÃ¶chte, kÃ¶nnte dann ebenfalls nicht Ã¼ber den Chatbot gesteuert werden.

Neben dem technisch-funktionalen Vorgehen stellt man im Laufe der Verwendung vielleicht auch fest, dass man Optimierungen haben mÃ¶chte. Man kann das Modell ja nicht nur neu trainieren, weil GerÃ¤te hinzugefÃ¼gt oder gelÃ¶scht wurden, sondern man mÃ¶chte vielleicht andere Eingaben nutzen, mÃ¶gliche Synonyme usw., weil man ja viele SÃ¤tze nie gleich formuliert. Mit unterschiedlichen SÃ¤tzen mÃ¶chte man aber am Ende unter UmstÃ¤nde das gleiche Ergebnis erzielen. Wenn man dies entsprechend konfigurieren und trainieren kann, hilft dies, die Anwendung benutzerfreundlicher und individueller fÃ¼r den/die Anwender zu gestalten.

---

### **Was ist das Ziel?**

* **Verstehen von Benutzeranfragen**: Die KI soll in der Lage sein, einfache Anfragen zu verstehen (z.â€¯B. â€Wie ist die Temperatur im Wohnzimmer?â€œ oder â€Schalte das Licht einâ€œ).
* **Interaktion mit openHAB**: Die KI muss diese Anfragen verarbeiten und dann die entsprechenden Aktionen in openHAB auslÃ¶sen (z.â€¯B. den Status von Items abfragen oder Befehle an openHAB senden).

---

### **MÃ¶glichkeiten der KI-Entwicklung fÃ¼r diesen Anwendungsfall**

1. **TensorFlow (und Keras)**:
   TensorFlow ist ein sehr mÃ¤chtiges Framework fÃ¼r maschinelles Lernen und kÃ¶nnte verwendet werden, um **ein Modell fÃ¼r Textklassifikation** oder **Intent-Erkennung** zu trainieren. Du kÃ¶nntest ein Modell erstellen, das Eingaben (z.â€¯B. Benutzernachrichten) in bestimmte Kategorien einordnet und dann den entsprechenden Befehl fÃ¼r openHAB ausgibt.

   **Vorteile**:

   * FlexibilitÃ¤t und Leistung fÃ¼r komplexe Modelle.
   * GroÃŸe Community und viele Ressourcen.

   **Nachteile**:

   * TensorFlow kann relativ komplex sein und erfordert eine gewisse Einarbeitung, besonders bei Textdaten.

2. **Alternativen zu TensorFlow:**
   Hier sind einige andere Frameworks, die sich gut fÃ¼r Textklassifikation und Intent-Erkennung eignen:

   * **spaCy**: Ein schnelles und einfach zu verwendendes NLP-Framework. Es bietet viele vortrainierte Modelle und kann fÃ¼r Named Entity Recognition (NER), Textklassifikation und Intent-Erkennung verwendet werden.
   * **Rasa**: Eine End-to-End-NLP- und Dialog-Management-LÃ¶sung, die speziell fÃ¼r Chatbots entwickelt wurde. Mit Rasa kannst du ein Modell trainieren, das sowohl **Intents** (z.â€¯B. â€Temperatur abfragenâ€œ) als auch **EntitÃ¤ten** (z.â€¯B. â€Wohnzimmerâ€œ) erkennt und auf diese reagiert.
   * **Hugging Face Transformers**: Dies ist eine der modernsten NLP-Bibliotheken, die leistungsstarke vortrainierte Modelle wie GPT-3, BERT und T5 enthÃ¤lt. Damit kannst du ein Modell trainieren, das sowohl das Verstehen als auch das Generieren von Text Ã¼bernimmt.

---

### **Projektplanung und Struktur**

#### 1. **SystemÃ¼berblick**

* **Frontend (Flask + HTML/JS)**:

  * Web-OberflÃ¤che mit einem Login-System.
  * **Benutzer-Chat**: Normale Benutzer kÃ¶nnen mit dem Bot interagieren.
  * **Admin-Panel**: Admins kÃ¶nnen Daten fÃ¼r das Training hinzufÃ¼gen und das Modell neu trainieren.
  * **Datenbank (z.â€¯B. SQLite/MySQL)**: Speichern der Trainingsdaten, ChatverlÃ¤ufe, Synonym-Liste, Benutzeraccounts und Modelle.

* **Backend (Flask + Python)**:

  * Flask-Anwendung fÃ¼r die Kommunikation mit dem Frontend und die Verarbeitung der Anfragen.
  * **Modelltraining**: Das Backend wird in der Lage sein, das Modell basierend auf den eingegebenen Daten zu trainieren.
  * **Modell-API**: Ein API-Endpunkt, der auf Chat-Anfragen reagiert, basierend auf einem trainierten Modell.

* **Modell-Training (TensorFlow / Rasa / spaCy / Hugging Face)**:

  * Das Modell wird auf Basis der hinzugefÃ¼gten Trainingsdaten **dynamisch** trainiert.

#### 2. **BenÃ¶tigte Daten fÃ¼r das Modell-Training**

Um das Modell zu trainieren, benÃ¶tigen wir **beispielhafte Fragen (Intents)** und **EntitÃ¤ten**, die das Modell spÃ¤ter klassifizieren soll. Diese Daten kÃ¶nnen durch **manuelles HinzufÃ¼gen** im Admin-Bereich oder durch **automatisches Lernen** aus den Benutzer-Chat-Eingaben generiert werden.

##### Beispiel fÃ¼r Trainingsdaten (strukturierte Form)

Die **Trainingsdaten** bestehen aus zwei Hauptkomponenten:

* **Intents**: Was der Benutzer zu erreichen versucht (z.â€¯B. â€Temperatur abfragenâ€œ).
* **EntitÃ¤ten**: Bestimmte Informationen aus der Nachricht (z.â€¯B. â€Wohnzimmerâ€œ als Raumname).

###### Beispiel:

```json
{
    "intents": [
        {
            "intent": "Temperatur_abfragen",
            "examples": [
                "Wie ist die Temperatur im Wohnzimmer?",
                "Was ist die Temperatur im Schlafzimmer?",
                "Wie warm ist es im Wohnzimmer?"
            ],
            "entities": [
                {"entity": "Raum", "value": "Wohnzimmer"},
                {"entity": "Raum", "value": "Schlafzimmer"}
            ]
        },
        {
            "intent": "Licht_steuern",
            "examples": [
                "Schalte das Licht im Flur ein.",
                "Mach das Licht im Wohnzimmer an.",
                "Licht aus im Flur."
            ],
            "entities": [
                {"entity": "GerÃ¤t", "value": "Flur_Licht"},
                {"entity": "GerÃ¤t", "value": "Wohnzimmer_Licht"}
            ]
        }
    ]
}
```

##### ErklÃ¤rungen:

* **Intent**: Die allgemeine Bedeutung der Anfrage (z.â€¯B. â€Temperatur\_abfragenâ€œ oder â€Licht\_steuernâ€œ).
* **Examples**: Beispiele fÃ¼r Nachrichten, die dem Intent zugeordnet werden.
* **Entities**: Bestimmte EntitÃ¤ten (z.â€¯B. â€Wohnzimmerâ€œ, â€Flur\_Lichtâ€œ) aus den Beispielen.

Ebenfalls wird deutlich, warum man so etwas wie Synonyme benÃ¶tigt. Es kann z.B. heiÃŸen `Licht ein` oder `Licht an`.

---

#### 3. **Struktur der Anwendung**

* **Flask** verwaltet die Routen fÃ¼r die BenutzeroberflÃ¤che, den Chat und das Admin-Panel.
* **Datenbank** (z.â€¯B. SQLite oder MySQL): Speichert Benutzeranfragen und Trainingsdaten.

##### **Datenbanktabellen**

* **users**: Speichert Benutzer- und Admin-Daten (fÃ¼r Login).

  ```sql
  CREATE TABLE users (
      id INT PRIMARY KEY AUTO_INCREMENT,
      username VARCHAR(100),
      password VARCHAR(255),  -- Gespeichert als Hash
      role ENUM('user', 'admin')
  );
  ```

* **chat\_history**: Speichert Chatnachrichten zwischen Benutzern und dem Bot.

  ```sql
  CREATE TABLE chat_history (
      id INT PRIMARY KEY AUTO_INCREMENT,
      user_id INT,
      message TEXT,
      response TEXT,
      timestamp DATETIME,
      FOREIGN KEY (user_id) REFERENCES users(id)
  );
  ```

Rein theoretisch kÃ¶nnte man mit Reinforcement Learning auch den Chatverlauf fÃ¼r das Training wiederverwenden.

* **training\_data**: Speichert Trainingsdaten fÃ¼r das Modell.

  ```sql
  CREATE TABLE training_data (
      id INT PRIMARY KEY AUTO_INCREMENT,
      intent VARCHAR(100),
      example TEXT,
      entity VARCHAR(100),
      value VARCHAR(100)
  );
  ```

FÃ¼r **Synonyme** muss man nun ein bisschen komplizierter vorgehen. Hier reicht eine einzige Tabelle nicht aus. Man hat eine `n:m`-Beziehung, bedeutet man muss drei Tabellen anlegen.

Um eine Tabelle fÃ¼r Synonyme in SQL zu erstellen, solltest du eine Datenstruktur wÃ¤hlen, die flexible Beziehungen zwischen WÃ¶rtern erlaubt â€“ insbesondere eine **n\:m-Beziehung** (also viele zu vielen). Denn ein Wort kann mehrere Synonyme haben, und ein Synonym kann wiederum fÃ¼r mehrere WÃ¶rter gelten.

LÃ¶sung: Drei Tabellen

Du kannst drei Tabellen verwenden:

1. **`woerter`** â€“ Liste aller WÃ¶rter.
2. **`synonyme`** â€“ Liste aller Synonym-Gruppen oder Paarungen.
3. **`wort_synonym`** â€“ VerknÃ¼pfungstabelle, die die n\:m-Beziehung abbildet.

Beispielstruktur:

```sql
-- Tabelle fÃ¼r WÃ¶rter
CREATE TABLE woerter (
    id SERIAL PRIMARY KEY,
    wort TEXT NOT NULL UNIQUE
);

-- Tabelle fÃ¼r Synonymgruppen
CREATE TABLE synonymgruppen (
    id SERIAL PRIMARY KEY
);

-- VerknÃ¼pfungstabelle zwischen WÃ¶rter und Synonymgruppen
CREATE TABLE wort_synonym (
    wort_id INT REFERENCES woerter(id),
    synonymgruppe_id INT REFERENCES synonymgruppen(id),
    PRIMARY KEY (wort_id, synonymgruppe_id)
);
```

Beispiel fÃ¼r die Nutzung:

Wenn du z.â€¯B. eine Synonymgruppe fÃ¼r â€Autoâ€œ, â€Wagenâ€œ und â€Fahrzeugâ€œ erstellen willst:

```sql
-- WÃ¶rter einfÃ¼gen
INSERT INTO woerter (wort) VALUES ('Auto'), ('Wagen'), ('Fahrzeug');

-- Neue Synonymgruppe erstellen
INSERT INTO synonymgruppen DEFAULT VALUES;

-- IDs abfragen
SELECT id FROM synonymgruppen ORDER BY id DESC LIMIT 1; -- z.â€¯B. id = 1
SELECT id FROM woerter WHERE wort IN ('Auto', 'Wagen', 'Fahrzeug'); -- z.â€¯B. 1,2,3

-- VerknÃ¼pfungen herstellen
INSERT INTO wort_synonym (wort_id, synonymgruppe_id) VALUES
(1, 1), (2, 1), (3, 1);
```

Abfragebeispiel: Synonyme fÃ¼r â€Autoâ€œ finden

```sql
SELECT w2.wort
FROM woerter w1
JOIN wort_synonym ws1 ON w1.id = ws1.wort_id
JOIN wort_synonym ws2 ON ws1.synonymgruppe_id = ws2.synonymgruppe_id
JOIN woerter w2 ON ws2.wort_id = w2.id
WHERE w1.wort = 'Auto' AND w2.wort != 'Auto';
```

Alternative: Direkte Paarweise Speicherung (nur bei einfacher Beziehung)

Falls du nur einfache paarweise Synonyme speichern willst (weniger flexibel):

```sql
CREATE TABLE synonyme (
    wort1 TEXT NOT NULL,
    wort2 TEXT NOT NULL,
    PRIMARY KEY (wort1, wort2)
);
```

Das ist allerdings bei grÃ¶ÃŸeren Synonymgruppen schwer wartbar und schlecht erweiterbar.

Eventuell ergibt es sogar Sinn, dass man Synonyme nicht in einzelne Worte denkt, sondern vielleicht in ganzen SÃ¤tze oder TeilsÃ¤tze.

Wie genau eine Tabelle fÃ¼r **Modelle** aussieht, hÃ¤ngt letzen Endes sehr stark von dem entwickelten Modell ab. Dies ist dann auch unter UmstÃ¤nden abhÃ¤ngig davon, ob man z. B. spaCy verwendet oder Tensorflow, usw. Vorteile der Speicherung der Modelle hat es, dass man nicht nur zwangslÃ¤ufig das zuletzt trainierte Modell verwenden kann. Man kÃ¶nnte z. B. im Benutzerchat eine Funktion anbieten, mit der man zwischen den Modellen wechselt (Ã¤hnlich, wie z. B. bei ChatGPT). Auch kÃ¶nnen Ã¤ltere Modellversionen mÃ¶glicherweise auch fÃ¼r ein Reinforcement Learning verwendet werden. Im Zweifelsfall kann auch eine Datenbanktabelle fÃ¼r Modelle einfach auch nur als Backup dienen.

Nach einem Training soll das Modell am besten automatisch in eine Datenbank gespeichert werden. Es empfiehlt sich, dass ein Zeitstempel des letzten Trainings gespeichert wird und das es vielleicht ein Feld mit Versionsnummer gibt, welches automatisch iteriert (Das neueste Modell hat immer eine hÃ¶here Zahl, als das vorherige. Hier empfiehlt es sich `Integer` als Datentyp zu verwenden).

---

#### 4. **Funktionsweise des Admin-Panels**

* **Admin-Panel**:

  * **Daten hinzufÃ¼gen**: Admins kÃ¶nnen neue **Intents** und **Beispiel-Fragen** hinzufÃ¼gen (Ã¼ber ein Webformular).
  * **Synonyme hinzufÃ¼gen**: Admins kÃ¶nnen neue **Synonyme** hinzufÃ¼gen (Ã¼ber ein Webformular).  
  * **Modell-Training starten**: Ein Button zum Starten des Trainingsprozesses. Nach Klick wird der Backend-Prozess angestoÃŸen, der die Trainingsdaten nimmt und das Modell trainiert. (Ein neues Modell soll nachdem Training automatisch in die Datenbank gespeichert werden)

  ##### **Beispiel fÃ¼r ein Admin-Formular**:

  * **Intent**: Auswahl eines vorhandenen Intents oder Eingabe eines neuen Intents.

  * **Beispiel-Fragen**: Textfeld, in das Admins neue Fragen eingeben kÃ¶nnen, die dem Intent zugeordnet werden.

  * **EntitÃ¤ten**: Eingabefelder fÃ¼r die EntitÃ¤ten (z.â€¯B. Raumnamen oder GerÃ¤te).

  * **Button â€Trainierenâ€œ**: Wenn der Admin auf diesen Button klickt, wird der Trainingsprozess angestoÃŸen.

Ein Beispiel fÃ¼r das Speichern der Synonym-Liste lasse ich hier ausnahmsweise weg. Ergibt sich aus den Datenbanktabellen.

---

#### 5. **Automatisiertes Lernen aus Chatnachrichten**

Um das Modell **dynamisch** zu trainieren, kÃ¶nnen auch **Benutzereingaben** als Trainingsdaten verwendet werden. Dies kÃ¶nnte so ablaufen:

* **Interaktionen speichern**: Jede Nachricht, die der Benutzer sendet, wird zusammen mit der Antwort des Bots in der **Datenbank** gespeichert.
* **Trainingsdaten generieren**: Ein Admin kann dann alle gespeicherten Benutzernachrichten durchsuchen und entscheiden, ob diese in das Training aufgenommen werden sollen.
* **Verfeinerung**: Nach einer gewissen Anzahl von Interaktionen kann das Modell mit diesen neuen Beispielen neu trainiert werden, um auf hÃ¤ufig gestellte Fragen und neue Anfragen besser zu reagieren.

---

#### 6. **Trainingsprozess**

* **Button â€Trainierenâ€œ**: Wenn der Admin den Button klickt, wird das System:

  * Die aktuellen Trainingsdaten aus der Datenbank abrufen.
  * Das Modell (z.â€¯B. TensorFlow oder spaCy) mit den neuen Daten trainieren.
  * Die neuen Modellparameter speichern und das aktualisierte Modell im Backend bereitstellen.

Auch hier muss man sich mÃ¶glicherweise Ã¼berlegen, ob man die Modellparameter oder das ganze Modell speichert. Vermutlich ergibt sogar beides Sinn. Die Modellparameter kÃ¶nnen ja Ã¼ber andere Tabellen bereits gespeichert sein und wÃ¼rden fÃ¼r ein erneutes Training ja bereits ausreichen.

---

#### 7. **Projektaufbau (Workflow)**

* **Login**: Benutzer und Admins melden sich an.
* **Benutzer-Chat**: Normale Benutzer kÃ¶nnen mit dem Bot interagieren, ihre Nachrichten werden gespeichert.
* **Admin-Paneel**: Admins kÃ¶nnen Daten fÃ¼r das Training hinzufÃ¼gen und das Modell trainieren.
* **Training starten**: Admin klickt auf â€Trainierenâ€œ, um das Modell mit neuen Daten zu trainieren.
* **Modell verwenden**: Sobald das Modell trainiert ist, wird es fÃ¼r die Chatbot-Interaktionen verwendet.

---

#### 8. **Dynamisches Lernen im Chat**

Um das Modell kontinuierlich zu verbessern, kÃ¶nnten Benutzereingaben nach einer **BestÃ¤tigung** durch den Admin ins Training aufgenommen werden. Dies wÃ¤re eine Form des â€**aktiven Lernens**â€œ (engl. **active learning**).

#### **Zusammenfassung**:

Das System kÃ¶nnte folgendermaÃŸen aufgebaut werden:

1. **Frontend** (Flask + HTML/JS) fÃ¼r den Chat und Admin-Bereich.
2. **Backend** (Flask + Python) zur Verarbeitung von Nachrichten und Verwaltung des Trainingsprozesses.
3. **Datenbank** zur Speicherung von Benutzerinformationen, Chats und Trainingsdaten.
4. **Modelltraining** Ã¼ber einen Admin-Button, der das Modell mit den neuesten Trainingsdaten aktualisiert.

**Wichtige Schritte fÃ¼r den Aufbau**:

1. Design und Implementierung der **Datenbankstruktur**.
2. Aufbau der **Flask-Anwendung** fÃ¼r den Chat und das Admin-Panel.
3. Erstellung der **Trainingslogik** und Integration des **KI-Modells**.
4. Erstellung der **Admin-OberflÃ¤che** zur Verwaltung von Trainingsdaten und Training des Modells.

Ich denke dies ist bislang nur ein Vorschlag zum Systementwurf. Der ist relativ prÃ¤zise. WÃ¤hrend der Bearbeitung entstehen aber mÃ¶glicherweise andere Anforderungen bzw. man wird feststellen, dass man manche Dinge vielleicht etwas anders strukturieren und entwickeln muss. Dieses Vorgehen soll jedoch erlÃ¤utern, wie man sich das geplante System in etwa vorstellen kÃ¶nnen soll.

---

### **Ansatz: KI-gestÃ¼tzter Chatbot mit TensorFlow (oder Alternativen)**

#### 1. **Daten sammeln**:

Um ein Modell zu trainieren, musst du zunÃ¤chst eine Datenbasis aufbauen, die aus **Beispiel-Fragen** und den dazugehÃ¶rigen **Befehlen** besteht. Diese Daten kÃ¶nnten aussehen wie:

```plaintext
Frage: "Wie ist die Temperatur im Wohnzimmer?"
Befehl: "GET:Wohnzimmer_Temperatur"

Frage: "Schalte das Licht im Flur ein."
Befehl: "SET:Flur_Licht:ON"
```

Datenbeispiel fÃ¼r das Training (Absicht + EntitÃ¤t):

```plaintext
"Wie ist die Temperatur im Wohnzimmer?" -> Intent: "Temperatur_abfragen", Entity: "Wohnzimmer"
"Schalte das Flurlicht ein." -> Intent: "Licht_steuern", Entity: "Flur_Licht", Action: "ON"
```

#### 2. **Modell mit TensorFlow trainieren**:

##### a. **Daten vorbereiten**:

Du kannst den Text in **numerische Features** umwandeln, z.â€¯B. mit einem **Tokenizer** oder einer **Word Embedding**-Methode (wie Word2Vec oder GloVe), um ein Modell zu trainieren.

##### b. **Modellarchitektur**:

FÃ¼r Textklassifikation eignet sich eine **Neural Network Architektur**, die auf **Recurrent Neural Networks (RNNs)** oder **Long Short-Term Memory (LSTM)** basiert. Eine andere MÃ¶glichkeit ist die Verwendung von **Convolutional Neural Networks (CNNs)**, die ebenfalls bei Textklassifikationen gut funktionieren.

Hier ist ein grundlegendes Beispiel, wie ein **Textklassifikator** in TensorFlow mit **Keras** aussehen kÃ¶nnte:

##### Beispielcode mit TensorFlow (LSTM):

```python
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

# Beispiel-Daten: Frage-Antwort-Paare
questions = [
    "Wie ist die Temperatur im Wohnzimmer?",
    "Schalte das Licht im Flur ein.",
    "Wie ist die Temperatur im Schlafzimmer?",
    "Schalte das Wohnzimmerlicht aus."
]

labels = [
    "GET:Wohnzimmer_Temperatur",
    "SET:Flur_Licht:ON",
    "GET:Schlafzimmer_Temperatur",
    "SET:Wohnzimmer_Licht:OFF"
]

# Tokenizer initialisieren
tokenizer = Tokenizer()
tokenizer.fit_on_texts(questions)
sequences = tokenizer.texts_to_sequences(questions)
X = pad_sequences(sequences, padding='post')

# Labels in numerische Form umwandeln
label_to_id = {label: idx for idx, label in enumerate(set(labels))}
y = np.array([label_to_id[label] for label in labels])

# Modell erstellen (LSTM)
model = models.Sequential([
    layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=X.shape[1]),
    layers.LSTM(64),
    layers.Dense(32, activation='relu'),
    layers.Dense(len(label_to_id), activation='softmax')
])

# Modell kompilieren und trainieren
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, y, epochs=10, batch_size=2)

# Vorhersage treffen
def predict_intent(message):
    sequence = tokenizer.texts_to_sequences([message])
    padded = pad_sequences(sequence, padding='post', maxlen=X.shape[1])
    pred = model.predict(padded)
    predicted_label = np.argmax(pred)
    return list(label_to_id.keys())[predicted_label]

# Beispiel-Nachricht
message = "Schalte das Licht im Flur ein."
predicted_command = predict_intent(message)
print("Vorhergesagter Befehl:", predicted_command)
```

Bitte beachte, dass dies nur Pseudocode ist, welcher nicht in eine Gesamtstruktur eingebunden ist.

#### 3. **Daten fÃ¼r Training erweitern**:

Die QualitÃ¤t des Modells hÃ¤ngt von der Menge und Vielfalt der Trainingsdaten ab. Du kannst die Daten erweitern, indem du mehr Fragen und Antworten hinzufÃ¼gst. Hier sind einige Beispiele:

```plaintext
Frage: "Wie ist die Temperatur im Wohnzimmer?"
Frage: "Wie hoch ist die Temperatur im Wohnzimmer?"
Frage: "Wie warm ist es im Wohnzimmer?"

Frage: "Schalte das Licht im Flur aus."
Frage: "Mach das Licht im Flur aus."
Frage: "Flurlicht aus"
```

Du kannst auch **Datenaugmentation** verwenden, um deine Trainingsdaten zu erweitern und das Modell robuster zu machen.

---

#### **Alternativen zu TensorFlow**

Wie bereits erwÃ¤hnt, gibt es auch **andere Tools** wie **Rasa** oder **spaCy**, die sich speziell auf die Entwicklung von Chatbots konzentrieren und dir viele vorgefertigte Modelle und Funktionen bieten, um die Absicht und EntitÃ¤ten zu erkennen.

* **Rasa**:

  * Open-Source-NLP-Framework fÃ¼r Chatbots.
  * Bietet eine einfache MÃ¶glichkeit, **Intents** und **EntitÃ¤ten** zu definieren und zu trainieren.
  * UnterstÃ¼tzt **Sprachdialoge** und kann auch mit openHAB kombiniert werden.
* **spaCy**:

  * Schnelles und modernes NLP-Toolkit.
  * Sehr gut fÃ¼r Named Entity Recognition (NER) geeignet und kÃ¶nnte helfen, die verschiedenen GerÃ¤te und Werte in deinen Fragen zu erkennen.
* **Hugging Face**:

  * Diese Bibliothek ist besonders leistungsfÃ¤hig, wenn du ein **Transformers-Modell** wie BERT oder GPT-2 einsetzen mÃ¶chtest, um kontextuelle Bedeutung zu verstehen.

---

##### **Zusammenfassung**:

* **TensorFlow** ist eine starke Wahl fÃ¼r das Trainieren eines **Custom NLP-Modells** zur Intent-Erkennung, benÃ¶tigt aber viele Trainingsdaten und Anpassung.
* **spaCy** oder **Rasa** bieten dir einfachere Alternativen fÃ¼r einen Chatbot, die spezifische Tools fÃ¼r **Intent-Erkennung und Dialog-Management** bieten.
* **Hugging Face** kÃ¶nnte eine sehr mÃ¤chtige Option sein, wenn du tiefer in vortrainierte Modelle wie BERT oder GPT einsteigen mÃ¶chtest.

Wenn du ein **leichtgewichtiges, spezialisiertes Modell** benÃ¶tigst, wÃ¼rde ich dir zu **Rasa** oder **spaCy** raten. Durch Recherche kann man ggf. auch weitere KI-Technologien in Betracht ziehen. Dies gilt hier lediglich nur als Vorschlag.

---

### Exkurs: Wie funktioniert das ohne KI?

Es ist nicht empfohlen auf eine **KI** zu verzichten. Man kann (besser gesagt kÃ¶nnte) aber den Chatbot so gestalten, dass er auf bestimmte, vordefinierte Fragen oder Befehle reagiert, basierend auf einer **regelbasierten Logik**. Das bedeutet, der Bot erkennt bestimmte Muster in der Benutzereingabe und lÃ¶st daraufhin entsprechende Aktionen in openHAB aus.

Das wÃ¤re ein einfacherer Ansatz, der keine externe KI benÃ¶tigt. Dies bedeutet aber, dass ein Benutzer keine individuellen Abweichungen sich erlauben kann. Es wÃ¼rde exakt ein einziger vordefinierter Satz geben und sollte dieser erkannt werden, wird entsprechend darauf reagiert. Man kann auch listenbasiert vorgehen, wie z. B., dass in einem Satz vier oder fÃ¼nf WÃ¶rter vorkommen muss. Dann wÃ¤re egal, welcher Satz genau eingegeben wurde, sobald diese vier oder fÃ¼nf WÃ¶rter vorkommen, wird dann die entsprechende Regel damit getriggert. Wenn man nur eine Liste mit ein oder zwei WÃ¶rtern hat, kann man die SÃ¤tze nicht gut genug voneinander unterscheiden. Hat man wiederum eine Liste mit zu vielen WÃ¶rtern, dann ist es ebenfalls denkbar, dass der Benutzer es nicht schafft, einen geeigneten Satz zu formulieren.

Genau dieser Umstand fÃ¼hrt dazu, dass man mit einer **regelbasierten Logik** nur bis zu einem gewissen Punkt gut arbeiten kann. Je komplexer die Anforderungen des Benutzers sind, desto mehr wird eine **KI** notwendig.

---

#### ğŸ›  Beispiel fÃ¼r einen **regelbasierten Chatbot** in Python mit Flask

In diesem Beispiel reagiert der Bot auf vordefinierte Fragen wie:

* â€Wie ist die Temperatur im Wohnzimmer?â€œ
* â€Schalte das Licht im Flur ein.â€œ

Der Bot nutzt **Python** und **Flask** als Backend, um Ã¼ber die openHAB REST API mit deinem Smart Home zu kommunizieren.

Die SÃ¤tze mÃ¼ssten in diesem Beispiel relativ exakt so formuliert werden, sonst wÃ¼rde keine Antwort erfolgen.

##### ğŸ”§ 1. Backend in Flask

```python
from flask import Flask, render_template, request, jsonify
import requests

# === Konfiguration ===
OPENHAB_BASE_URL = 'http://openhab.local:8080/rest'  # openHAB-URL anpassen
TEMPERATURE_ITEM = 'Wohnzimmer_Temperatur'  # openHAB Item fÃ¼r Temperatur

app = Flask(__name__)

# === openHAB: Status abfragen ===
def get_item_state(item_name):
    try:
        response = requests.get(f"{OPENHAB_BASE_URL}/items/{item_name}/state")
        response.raise_for_status()
        return response.text
    except Exception as e:
        return f"Fehler: {e}"

# === openHAB: Item setzen ===
def set_item_state(item_name, command):
    try:
        response = requests.post(f"{OPENHAB_BASE_URL}/items/{item_name}", data=command,
                                 headers={'Content-Type': 'text/plain'})
        response.raise_for_status()
        return "OK"
    except Exception as e:
        return f"Fehler: {e}"

# === Regelbasierte Logik fÃ¼r den Chatbot ===
def process_message(user_message):
    user_message = user_message.lower()

    if "temperatur" in user_message and "wohnzimmer" in user_message:
        state = get_item_state(TEMPERATURE_ITEM)
        return f"Die aktuelle Temperatur im Wohnzimmer betrÃ¤gt: {state}Â°C."

    elif "licht" in user_message and "flur" in user_message and "ein" in user_message:
        result = set_item_state('Flur_Licht', 'ON')
        return f"Das Licht im Flur wurde eingeschaltet. Ergebnis: {result}"

    elif "licht" in user_message and "flur" in user_message and "aus" in user_message:
        result = set_item_state('Flur_Licht', 'OFF')
        return f"Das Licht im Flur wurde ausgeschaltet. Ergebnis: {result}"

    else:
        return "Entschuldigung, das habe ich nicht verstanden. Versuche es mit einer anderen Anfrage."

# === Routen ===
@app.route("/")
def index():
    return render_template("chat.html")

@app.route("/chat", methods=["POST"])
def chat():
    user_message = request.json.get("message", "")
    reply = process_message(user_message)
    return jsonify({"reply": reply})

if __name__ == "__main__":
    app.run(debug=True)
```

Man kann den nachfolgenden Teil kÃ¼rzen:

```python
elif "licht" in user_message and "flur" in user_message and "aus" in user_message:
```

Dieser kÃ¶nnte auch wie folgt dann aussehen:

```python
elif ["licht", "flur", "aus"] in user_message:
```

Idealerweise wÃ¼rde man hier natÃ¼rlich auch die Worte aus einer Datenbank auslesen und Regeln Ã¼ber Datenbanken erstellen lassen. Auch eine MÃ¶glichkeit fÃ¼r Synonyme wÃ¤re, dass man z. B. `flur` und `Flur` erlaubt. Ebenfalls mÃ¶glich ist es, dass man alle Worte einheitlich zu klein Ã¤ndert, damit man die GroÃŸ-/Kleinschreibung als Fehlerquelle elementiert. Dies kann ja auch mal versehentlich durch Tippfehler bei der Chateingabe entstehen.

In diesem Beispiel ist jetzt die Verarbeitung der Chateingabe statisch. Durch eine Verwendung einer Datenbank, kÃ¶nnte man diesen Teil dann bereits dynamisch gestalten. SpÃ¤testens wenn an dieser Stelle eine **KI** angedockt wird, wird man um eine dynamische Verarbeitung nicht drumherum kommen.

In dem gekÃ¼rzten Teil sieht man, dass auch eine Liste verwendet werden kann. Schaue ich mir den ersten Teilcode an, dann sehe ich eine **UND**-VerknÃ¼pfung. Auch so kÃ¶nnte man sich vorstellen, dass anstelle eines Wortes jedesmal eine Synonym-Liste verwendet wird. Man kÃ¶nnte ja ein Wort abfragen und eine Liste mit allen Synonymen zurÃ¼ckgeben. Wenn man Listen verwendet, dann kann ich auch eine Liste mit einer anderen Liste ergÃ¤nzen, was ebenfalls eine MÃ¶glichkeit wÃ¤re, um Synonyme fÃ¼r eine ÃœberprÃ¼fung einzupflegen.

#### ğŸ”§ 2. Frontend in HTML (chat.html)

```html
<!DOCTYPE html>
<html>
<head>
  <title>openHAB Chatbot</title>
  <script>
    async function sendMessage() {
      const input = document.getElementById("message");
      const chat = document.getElementById("chat");

      const userText = input.value;
      chat.innerHTML += "<b>Du:</b> " + userText + "<br>";

      const response = await fetch("/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message: userText })
      });

      const data = await response.json();
      chat.innerHTML += "<b>Bot:</b> " + data.reply + "<br><br>";
      input.value = "";
    }
  </script>
</head>
<body>
  <h1>ğŸ’¬ openHAB Chatbot</h1>
  <div id="chat" style="border:1px solid #ccc; padding:10px; height:300px; overflow:auto;"></div>
  <input type="text" id="message" placeholder="Nachricht..." onkeydown="if(event.key==='Enter')sendMessage()" />
  <button onclick="sendMessage()">Senden</button>
</body>
</html>
```

Ich empfehle grundlegend, wenn man ein Frontend verwendet, dass man am besten etwas vorgefertigtes nutzt. Es gilt mittlerweile als Standard, dass man das Frontend-Framework [Bootstrap](https://getbootstrap.com/) nutzt. Dann hat man nicht nur schon ein schÃ¶nes und vorgefertigtes Desing, sondern kann auch bereits auf einige nÃ¼tzliche JavaScript-Funktionen zurÃ¼ckgreifen. Dies gibt dem Gestalter auch fÃ¼r Interaktionen bessere MÃ¶glichkeiten.

---

#### ğŸ” Was passiert hier?

1. **Flask Backend**:

   * Wenn ein Benutzer eine Nachricht sendet, wird diese vom Server verarbeitet.
   * Der Bot sucht nach bestimmten SchlÃ¼sselwÃ¶rtern (z.â€¯B. â€Temperaturâ€œ, â€Lichtâ€œ, â€Flurâ€œ).
   * Je nach Nachricht ruft der Bot entweder den **Status eines Items** ab oder sendet einen **Befehl an openHAB**, um ein GerÃ¤t zu steuern.

2. **Frontend (HTML)**:

   * Du hast eine einfache BenutzeroberflÃ¤che, in der du Nachrichten eingeben kannst.
   * Die Antwort des Bots wird unter der Chatbox angezeigt.

---

#### ğŸ’¡ ErweiterungsmÃ¶glichkeiten

* **Weitere GerÃ¤te und Items**: Du kannst den Bot um weitere openHAB-GerÃ¤te (z.â€¯B. Heizungen, Jalousien) erweitern, indem du zusÃ¤tzliche Bedingungen in der `process_message`-Funktion hinzufÃ¼gst.
* **Sprachsteuerung**: Du kÃ¶nntest auch Spracherkennung (z.â€¯B. mit der Google Speech-to-Text API) hinzufÃ¼gen, um die Nachrichten per Sprache zu senden.
* **Nutzerfreundlichkeit**: Erweiterungen wie die MÃ¶glichkeit, mehrere GerÃ¤te zu steuern oder zu kombinieren (z.â€¯B. â€Schalte das Wohnzimmerlicht und die Heizung anâ€œ).

Weitere GerÃ¤te und Items lassen sich sehr viel schÃ¶ner natÃ¼rlich durch eine Datenbank hinzufÃ¼gen. Hier dann entsprechend gleich mit ihrer Regel. Die Nutzerfreundlichkeit ist meiner Meinung nach hier nicht ideal. Mit einer Datenbank wird dies schÃ¶ner, weil man nicht den Programmcode Ã¤ndern muss, sondern der Benutzer kann das Programm durch eine WeboberflÃ¤che erweitern.

---

#### Fazit

In diesem Szenario brauchst du keine KI, sondern baust einen **regelbasierten Chatbot**, der auf spezifische Eingaben reagiert. Der Vorteil ist, dass du die volle Kontrolle Ã¼ber die FunktionalitÃ¤ten hast, ohne auf komplexe KI-Systeme angewiesen zu sein. Nachteile sind, dass dies nicht dynamisch ist (eine Datenbank wÃ¼rde abhilfe schaffen) und man nur eingeschrÃ¤nkte Chateingaben zulassen kÃ¶nnte.

---



## ğŸ§  Zusammenfassung:

* âœ… Trennung von Benutzer-UI und Admin-UI (ggf. kann man ja noch andere Dienste, wie einen Sprachassistenten anbinden).
* âœ… Zentrale API mit klaren Funktionen
* âœ… Zukunftssicher durch Sprachintegration und weitere Clients
* âœ… Bessere Sicherheit, Wartbarkeit und Erweiterbarkeit

# Hintergrundwissen

## Fuzzy Matching

Das **Fuzzy Matching** kann man im deutschen als unscharfe Suche betiteln. Es ist eine Klasse von String-Matching-Algorithmen, mit der man bestimmte Zeichenketten (Strings) in einer lÃ¤ngeren Zeichenkette oder einem Text suchen bzw. finden kÃ¶nnen sollte.  Es wird daher auch oft als Fuzzy-Suche oder Fuzzy-String-Suche betitelt.

Aus:

[https://www.klippa.com/de/blog/informativ/fuzzy-matching-de/](https://www.klippa.com/de/blog/informativ/fuzzy-matching-de/)

Mit Fuzzy-Matching kann ich darauf reagieren, wenn z. B. nur 80% eines Wortes/Satzes richtig erkannt wurde. Hier mal Beispiele.

```
Gesucht: Bestellnummer

Richtig wÃ¤ren:
Bestellnr.
Bestelnummer
Bestellnumer
Bestellnummmer
...
```

Also mÃ¶gliche Tippfehler oder auch AbkÃ¼rzungen sollen ja darufhin deuten, dass ein- und dasselbe Worte gemeint ist. In Zusammenhang mit Synonymen wÃ¼rde man durch Fuzzy Matching dem Benutzer so extrem viele EingabemÃ¶glichkeiten ermÃ¶glichen. Man formuliert ja nicht nur SÃ¤tze um, man vertippt sich auch mal oder kÃ¼rzt einzelne WÃ¶rter ab.

**Fuzzy Matching** nimmt also Korrekturen vor. Dies kÃ¶nnten im allgemeinen die nachfolgenden sein:

* **EinfÃ¼gen** â€“ HinzufÃ¼gen eines Buchstabens zur VervollstÃ¤ndigung des Wortes (z. B. `Rechnun` wird zu `Rechnung`)
* **LÃ¶schen** â€“ Entfernen eines Buchstabens aus einem Wort (z. B. `Rechnnung` wird zu `Rechnung`)
* **Substitution** â€“ Vertauschen eines Buchstabens, um ein Wort zu korrigieren (z. B. `Technung` wird zu `Rechnung`)
* **Transposition** â€“ Vertauschen von Buchstaben, um ein Wort zu korrigieren (z. B. `Rehcnung` wird zu `Rechnung`)

Jeder Korrektur, die durchgefÃ¼hrt werden muss, wird eine â€Bearbeitungsdistanzâ€œ von 1 zugeschrieben. Die Bearbeitungsdistanzen beeinflussen die oben erwÃ¤hnte Trefferquote. Wenn Sie beispielsweise eine Zeichenfolge mit 11 Zeichen haben und 2 Korrekturen vornehmen mÃ¼ssen, betrÃ¤gt die endgÃ¼ltige Trefferquote **81,81 %**.

```
Berechnung: 100%- 2 / 11= 81.81%  
```

Neben diesen Korrekturen kann **Fuzzy Matching** auch verwendet werden, um Zeichensetzungen, zusÃ¤tzliche WÃ¶rter und fehlende Leerzeichen in Zeichenketten oder Texten zu korrigieren.

### Fuzzy-Matching-Algorithmen

Fuzzy Matching fÃ¤llt in die Kategorie der Methoden, fÃ¼r die es keinen spezifischen Algorithmus gibt, der alle Szenarien und AnwendungsfÃ¤lle abdeckt. Daher werden wir einige der am hÃ¤ufigsten verwendeten und zuverlÃ¤ssigsten Fuzzy-Matching-Algorithmen fÃ¼r die Suche nach ungefÃ¤hren DatenÃ¼bereinstimmungen behandeln:

* Levenshtein-Distanz (LD)
* Hamming-Distanz (HD)
* Damerau-Levenshtein

#### Levenshtein-Distanz

Die **Levenshtein-Distanz (LD)** ist eine Fuzzy-Matching-Technik, die zwei Zeichenfolgen beim Vergleich und der Suche nach einer Ãœbereinstimmung berÃ¼cksichtigt. Je hÃ¶her der Wert der Levenshtein-Distanz ist, desto weiter sind die beiden Zeichenfolgen oder â€Begriffeâ€œ von einer identischen Ãœbereinstimmung entfernt.

Wie erhalten wir nun den Wert der Levenshtein-Distanz? Die LD zwischen den beiden Zeichenfolgen entspricht der Anzahl der Ã„nderungen, die erforderlich sind, um eine Zeichenfolge in die andere umzuwandeln. FÃ¼r die LD gelten das EinfÃ¼gen, LÃ¶schen und Ersetzen eines einzelnen Zeichens als Bearbeitungsoperationen.

Nehmen wir an, Sie mÃ¶chten die LD zwischen â€Rechnungsnummerâ€œ und â€Rechnungs-Nr.â€œ messen. Der Abstand zwischen den beiden Begriffen ist â€1 x uâ€œ, â€2 x mâ€œ und â€1 x eâ€œ, was einem Abstand von 4 entsprechen wÃ¼rde. Warum? Weil Sie diese Zeichen hinzufÃ¼gen mÃ¼ssten, um eine Ãœbereinstimmung zu erreichen. Siehe die Beispiele unten.

##### Levenshtein-Abstand Beispiel

> **Rechnungnummer** â†’ Rechnung**s**nummer (EinfÃ¼gung von â€**s**â€œ) â€“ Abstand: 1  
> **Rechnung numr** â†’ Rechnungsnu**m**m**e**r (EinfÃ¼gung von â€**m**â€œ & â€**e**â€œ) â€“ Abstand: 2  
> **Rechnung nr** â†’ Rechnungsn**u****m****m****e**r (EinfÃ¼gung von â€**u, m, m, e**â€œ) â€“ Abstand: 4


#### Hamming-Distanz

Die **Hamming-Distanz (HD)** unterscheidet sich nicht allzu sehr von der Levenshtein-Distanz. Die Hamming-Distanz wird hÃ¤ufig verwendet, um den Abstand zwischen zwei gleich langen Textabschnitten zu berechnen.

Die HD-Methode basiert auf der **ASCII**-Tabelle (American Standard Code for Information Interchange). Zur Berechnung des Abstandswertes verwendet der Hamming-Distanz-Algorithmus die Tabelle, um den BinÃ¤rcode zu bestimmen, der jedem Buchstaben in den Zeichenketten zugeordnet ist.

##### Hamming-Abstand-Beispiel

Nehmen wir die folgenden Textzeichenfolgen â€Numberâ€œ und â€Lumberâ€œ als Beispiel. Wenn wir versuchen, den HD zwischen den Zeichenfolgen zu bestimmen, ist der Abstand nicht 1, wie es mit dem Levenshtein-Algorithmus der Fall wÃ¤re. Stattdessen wÃ¼rde er 10 betragen. Das liegt daran, dass die ASCII-Tabelle einen BinÃ¤rcode von **(1001110)** fÃ¼r den Buchstaben **N** und **(1001100)** fÃ¼r den Buchstaben **L** anzeigt.

Beispielrechnung:

> **D** = N â€“ L = 1001110 â€“ 1001100 = **10**


#### Damerau-Levenshtein

Das Damerau-Levenshtein-Verfahren misst auch den Abstand zwischen zwei WÃ¶rtern, indem es die erforderlichen Ã„nderungen misst, die vorgenommen werden mÃ¼ssen, um ein Wort an das andere anzupassen. Diese Ã„nderungen hÃ¤ngen von der Anzahl der Operationen ab, wie z. B. EinfÃ¼gung, LÃ¶schung oder Ersetzung eines einzelnen Zeichens oder Transposition zweier benachbarter Zeichen.

Hier unterscheidet sich die Damerau-Levenshtein-Distanz von der regulÃ¤ren Levenshtein-Distanz, da sie zusÃ¤tzlich zu den Einzelzeichen-Editieroperationen, auch Transpositionen berÃ¼cksichtigt, um eine ungefÃ¤hre Ãœbereinstimmung zu finden (Fuzzy Match).

##### Damerau-Levenshtein Beispiel

> **Zeichenfolge 1:** Re<strong>ch</strong>nun<strong>g</strong>  
> **Zeichenfolge 2:** Re<strong>hc</strong>nun  
>   
> **Operation 1:** Transposition â†’ Vertauschen der Zeichen â€**h**â€œ und â€**c**â€œ  
> **Operation 2:** EinfÃ¼gen eines â€**g**â€œ am Ende der Zeichenfolge 2


Da zwei Operationen erforderlich waren, um die beiden WÃ¶rter identisch zu gestalten, **betrÃ¤gt der Abstand 2**. Vereinfacht ausgedrÃ¼ckt zÃ¤hlt jede Operation wie EinfÃ¼gung, LÃ¶schung, Transposition usw. als ein Abstand von â€1â€œ. Mit der Levenshtein-Distanz mÃ¼ssten Sie jedoch drei Korrekturen vornehmen, was einem Abstand von 3 entspricht.

Alle oben genannten Fuzzy-Matching-Algorithmen unterscheiden sich natÃ¼rlich in der Art und Weise, wie die Bearbeitungsdistanz berechnet wird. Dies ist der Grund, warum es keinen FM-Algorithmus gibt, der fÃ¼r alle geeignet ist. Von den drei vorgestellten Algorithmen ist die Levenshtein-Distanz jedoch der am hÃ¤ufigsten verwendete FM-Algorithmus in der Datenverwaltung und Datenwissenschaft.

Empfehlung: In Python kann man die [fuzzywuzzy-Bibliothek](https://github.com/seatgeek/fuzzywuzzy) testen oder einen eigenen Algorithmus implementieren.

## Intent, Entity, Confidence Score

Aus:

[https://www.melibo.de/blog/was-sind-intent-und-entity](https://www.melibo.de/blog/was-sind-intent-und-entity)

### Intent

Intents, zu Deutsch â€Absichtenâ€œ, sind Zwecke oder Ziele, die in den Eingaben eines Kunden zum Ausdruck kommen, um z.B. eine Frage zu einer Retoure zu stellen. Durch die Erkennung der Absicht, die sich in der Kundeneingabe ausdrÃ¼ckt, versucht der KI-Chatbot den richtigen Dialog zu finden und die passende Ausgabe zu wÃ¤hlen. DafÃ¼r nutzen KI-Chatbots maschinelles Lernen, um in natÃ¼rlicher Sprache die vorher definierte Absicht (Intent) zu erkennen. [1] Einfach gesagt, Intents sind Fragen der User:innen, die dem Chatbot zu einem speziellen Thema gestellt werden und der Versuch des KI-Chatbots, die passende Antwort zu erkennen, um das Problem zu lÃ¶sen bzw. die Frage zu beantworten.

#### Wie funktionieren Intents?

Bestehende Anbieter wie unter anderem der IBM Watson Assistant [1], Rasa [2] oder Microsoft LUIS [3] basieren alle meist auf dem Prinzip der Intent-Ausgabe. Bevor der Chatbot Intents erkennen kann, mÃ¼ssen erst mal alle Absichten der User:innen definiert werden. HierfÃ¼r ist es wichtig, dass man seine Kundenanfragen erst mal identifiziert und seinen Use-Case richtig versteht. Nachdem der Intent-Katalog erstellt und der Bot online genommen wurde, werden die User:innen dem Chatbot Fragen stellen. Jede Anfrage der User:innen durchlÃ¤uft das sogenannte Intent-Matching, also der Zuordnung der Anfrage aus den gesamten Inhalten des Chatbots. Dabei wird anhand von NLP (Natural Language Processing) ein Confidence-Score berechnet, um anhand von Wahrscheinlichkeiten die passende Antwort auszugeben.

### Confidence-Score

Ein kurzer Exkurs zum Thema Confidence-Scores. Die Confidence-Scores liegen zwischen 0 und 1 und geben an, zu wie viel Prozent der Chatbot ein Intent erkannt hat. Zu jeder gestellten Frage der User:innen berechnet der Chatbot also einen Confidence-Score und versucht auf dieser Grundlage, durch Wahrscheinlichkeiten, die richtige Antwort an die User:innen auszugeben. Die Confidence-Scores sind meistens voreingestellt und liegen zwischen 0,6 und 0,7. Das heiÃŸt, dass der Chatbot Antworten nur dann ausgibt, wenn die Erkennungswahrscheinlichkeit bei mindestens 60 % liegt. Nehmen wir nun als Beispiel an, dass User:innen die Frage stellen â€Was kannst du so?â€œ, um zu erfahren, welche Themen der Chatbot Ã¼berhaupt beantworten kann. Der KI-Chatbot erkennt zu 89 % Prozent den Intent â€Was kannst du?â€œ. In diesem Beispiel gibt der Chatbot die passende Antwort aus und beantwortet somit die Frage.

#### Bestandteile eines Intents

Ein Intent besteht also aus dem: Intentnamen, dem User-Input, dem Confidence-Score und einer Antwort. AbhÃ¤ngig von der genutzten Technologie kÃ¶nnen noch weitere Bestandteile dazu kommen, wie Variablen, Actions und Entities.

Ein Beispiel fÃ¼r Intents

(1) User-Input: Frage eines Users

ğŸ™â€â™‚ï¸: â€Vorteile eines Chatbotsâ€œ
ğŸ™â€â™‚ï¸: â€Was kÃ¶nnen Chatbots besonders gut?â€œ
ğŸ™â€â™‚ï¸: â€Warum sollte ich einen Chatbot holen?â€œ

(2) Confidence-Score und (3) Intentnamen â€Vorteile Chatbotâ€œ: Berechnung der Wahrscheinlichkeit anhand vom User-Input

ğŸ§® : 100 % Erkennung des Intents â€Vorteile Chatbotâ€œ

(4) Antwort des Chatbots auf die Frage â€Vorteile Chatbotsâ€œ

ğŸ¤– : Zu den Vorteilen von Chatbots gehÃ¶ren unter anderem und abhÃ¤ngig von der Branche: Automatisierung von Prozessen, wodurch Fehler beim Support reduziert sowie Zeit und Geld eingespart werden kÃ¶nnen. VerkÃ¼rzte Wartezeiten fÃ¼r den Kunden. 24/7 Kundensupport. Effizientere Strukturen. Weniger manueller Aufwand fÃ¼r dich.

### Entity

Im Unterschied zu Intents dienen Entitys oder auch Entities dazu, Informationen der User:innen aus der natÃ¼rlichen Sprache zu extrahieren. Jedes Entity verfÃ¼gt Ã¼ber eine Reihe von Eigenschaften, die mit ihr verbunden sind. Dabei kannst du auf Informationen deines Entities zugreifen. Wie bei einem Intent gibt der Chatbot an, wie hoch der Confidence-Score liegt. Im Unterschied zu Intents liegt der Confidence-Score, aber bei 0 oder 1. UnabhÃ¤ngig davon, ob und wie die Erkennung des Entitys eingestellt ist, haben sogenannte System-Entites immer eine Erkennung von 1. Jedes Entity besitzt einen Wert, einen sogenannten EntitÃ¤tswert. Bei der Erstellung von Entities ist es notwendig, dass neben dem Wert auch Typen definiert werden. Unter Typen versteht man allgemein Synonyme, also WÃ¶rter, die sich ebenfalls auf dasselbe Vorhaben beziehen, es nur anders umschreiben. Je mehr Synonyme ein Entity hat, desto besser die Erkennung des Chatbots [4].

GrundsÃ¤tzlich unterscheiden wir zwischen System-Entities und Customize-Entities. Die System-Entites sind voreingestellt, das heiÃŸt im System bereits enthalten. Darunter fallen etwa Zahlen, Uhrzeiten oder Adressen. Diese Entities sind besonders beliebt und wurden in der Vergangenheit besonders hÃ¤ufig verwendet. Die Customize-Entities dagegen sind selbst definierte Werte, die auf den jeweiligen Use-Case angepasst werden.

#### Ein Beispiel fÃ¼r Entities in der Praxis

ğŸ™â€â™‚ï¸: â€Wann kommt mein Produkt Chatbot-Experte in der LandstraÃŸe 5 an?â€œ

#### Entities in diesem Beispiel:

Produkt Chatbot Experte (Customize-Entity product_type)
LandstraÃŸe 5 (Sytem-Entity street_adress)

#### Vorteile von Entites:

Mit Entities kann man User:innen durch Chat Flows in Form von Buttons navigieren, schnell Synonyme definieren und mehrere Anfragen auf einmal verarbeiten. Die System-Entitys helfen auÃŸerdem dabei, die beliebten Anfragen zum Thema Ort, Zeit und Adresse abzufangen.

[1]: https://cloud.ibm.com/docs/assistant?topic=assistant-intents
[2]: https://rasa.com/open-source/
[3]: https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-utterance
[4]: https://cloud.ibm.com/docs/assistant?topic=assistant-expression-language
