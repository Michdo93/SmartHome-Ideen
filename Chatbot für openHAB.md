# Konzeption und Implementierung eines webbasierten Chatbots mit trainierbarem KI-Modul zur Interaktion mit openHAB

---

## üéì **Titelvorschl√§ge f√ºr die Bachelorthesis**

1. **Entwicklung eines KI-gest√ºtzten Chatbots f√ºr Smart-Home-Steuerung mit Flask und selbsttrainierbarem Modell**
2. **Konzeption und Implementierung eines webbasierten Chatbots mit trainierbarem KI-Modul zur Interaktion mit openHAB**
3. **Webbasierte Benutzer- und Adminoberfl√§che f√ºr ein dynamisch lernf√§higes Chatbot-System im Smart-Home-Kontext**
4. **Design und Umsetzung eines selbstlernenden Chatbots mit dynamischem Training √ºber eine Admin-Weboberfl√§che**
5. **Architektur eines benutzerzentrierten KI-Systems zur Chat-basierten Steuerung von Smart Homes**
6. **Aufbau eines anpassbaren, KI-basierten Dialogsystems mit Flask und dynamischem Modelltraining f√ºr Smart Homes**
7. **Entwicklung eines KI-gest√ºtzten Chatbots mit dynamischem Training und Web-Oberfl√§che zur Smart-Home-Interaktion**
8. ...

Der Titel der Thesis muss erst kurz vor Abgabe endg√ºltig feststehen.

---

## üì£ **Ausschreibungstext f√ºr die Bachelorthesis**

### **Beschreibung:**

Im Rahmen dieser Bachelorarbeit soll ein interaktives Chatbot-System f√ºr die Steuerung von Smart-Home-Ger√§ten √ºber **openHAB** entwickelt werden. Die Besonderheit: Das System soll nicht auf statisch definierten Regeln oder externen KI-Diensten (wie ChatGPT) basieren, sondern eine **eigenst√§ndig trainierbare KI** verwenden, die √ºber eine **Weboberfl√§che von Administratoren gepflegt und erweitert werden kann**.

---

### **Ziele der Arbeit:**

* Entwurf und Umsetzung einer **Flask-basierten Webanwendung** mit zwei Benutzerrollen: Nutzer (Chat) und Administrator (Training).
* Integration einer **KI-Komponente**, die auf Basis von Benutzereingaben trainiert werden kann.
* Implementierung einer **Datenbank** zur Speicherung von Trainingsdaten, Chatverl√§ufen und Benutzerinformationen.
* Aufbau einer **Admin-Oberfl√§che**, √ºber die Intents, Entit√§ten und Beispiele eingegeben werden k√∂nnen.
* Dynamische Ausl√∂sung des Trainingsprozesses per Button in der Weboberfl√§che.
* Anbindung an openHAB √ºber die REST API zur Ausf√ºhrung realer Aktionen im Smart-Home-System.

---

### **Technologien & Tools:**

* **Programmiersprache**: Python
* **Frameworks**: Flask (Web), optional TensorFlow/Rasa/spaCy/Hugging Face (f√ºr die KI)
* **Datenbank**: SQLite oder MySQL
* **KI-Training**: Dynamisch √ºber das Admin-Interface
* **API-Kommunikation**: openHAB REST API

---

### **Voraussetzungen:**

* Gute Kenntnisse in Python
* Erste Erfahrungen mit Webentwicklung (Flask, HTML/JS)
* Interesse an k√ºnstlicher Intelligenz und maschinellem Lernen
* Selbstst√§ndiges Arbeiten und kreative Probleml√∂sung

---

### **Ergebnis der Arbeit:**

Ein **vollst√§ndig funktionierender Prototyp** eines KI-gest√ºtzten, webbasierten Chatbot-Systems zur Steuerung eines Smart Homes. Die Arbeit kann sp√§ter erweitert und als Open-Source-Projekt ver√∂ffentlicht werden.

---

## ‚úÖ Vorteile der Trennung von Benutzer-Chat, Admin-Panel und zentraler API

### 1. **Modularit√§t**

* **Frontend 1: Benutzer-Chat**

  * Eigene, schmale Oberfl√§che nur f√ºr Endnutzer.
* **Frontend 2: Admin-Panel**

  * Separat, gesch√ºtzt, mit anderen Funktionen (z.‚ÄØB. Datenpflege, Training).

‚Üí Beide greifen auf dieselbe **zentralisierte API** zu.

---

### 2. **Zentrale Kommunikationsschnittstelle (API-Gateway)**

Ein zentrales Backend (Flask API) dient als Schnittstelle f√ºr alle Clients:

```
Clients:
- Benutzer-Chat (Web)
- Admin-Panel (Web)
- Sprachassistent (z.‚ÄØB. Alexa, Raspberry Pi, Android-App)
- Mobile App
‚Üí alle √ºber eine einheitliche REST-API
```

Diese API regelt:

* Authentifizierung (JWT, OAuth, etc.)
* Datenverwaltung (Trainingsdaten, Logs)
* Chat-Dispatch: Anfrage ‚Üí Modell ‚Üí Antwort
* Trigger f√ºr Modelltraining
* Ger√§te-Interaktion (√ºber openHAB)

---

### 3. **Sprachassistent einfach integrierbar**

Dies w√§re in einem weiteren Projekt (weitere Thesis umsetzbar).

Es gilt:

* Chat-Eingabe ‚Üí ersetzt durch **Speech-to-Text**
* Chat-Ausgabe ‚Üí ersetzt durch **Text-to-Speech**

Dazu braucht der Client (z.‚ÄØB. in Python oder als App):

* Mikrofon ‚Üí STT (z.‚ÄØB. Google Speech, Whisper)
* Text senden ‚Üí REST-API
* Antwort empfangen ‚Üí TTS (z.‚ÄØB. pyttsx3, gTTS, ElevenLabs) ‚Üí Lautsprecher

---

## üß± Empfehlung: Systemaufbau (logisch)

![picture alt](https://raw.githubusercontent.com/Michdo93/SmartHome-Ideen/refs/heads/main/screenshots/chatbot.png)

### Idee

Aufbau eines **KI-gest√ºtzten Chatbots mit einer Web-Oberfl√§che** zur Verwaltung und **Training** in einem System wie **Flask**. Der Workflow w√ºrde sicherstellen, dass **Admins** das Modell trainieren k√∂nnen, ohne tief in den Code einzugreifen, sondern alles √ºber eine Benutzeroberfl√§che (Admin-Dashboard) steuern. Auch das dynamische **Trainieren des Modells** basierend auf neuen Benutzereingaben ist eine spannende Herausforderung.

Warum dieses Vorgehen?

Ein Smart-Home-System wie openHAB wird immer wieder erweitert. Es kommen neue Ger√§te und somit Things hinzu, zudem es entsprechend immer wieder neuere Items gibt. Eventuell werden alte Ger√§te ausgetauscht und gar entfernt, was dazu f√ºhrt, dass man die dazugeh√∂rigen Things und Items ebenfalls l√∂scht. F√ºr den Chatbot bedeutet dies, dass er nat√ºrlich immer nur auf den aktuellen Stand des Smart-Homes reagieren soll. Ein Chatbot, welches Informationen von alten Ger√§ten ausgeben m√∂chte, w√ºrde zum einen nichts bringen und zum anderen vermutlich gar keien Informationen zur√ºckliefern k√∂nnen. Ebenfalls w√§re der Versuch Ger√§te zu steuern, die gar nicht vorhanden sind fatal. Ein neues Ger√§t, welches man steuern m√∂chte, k√∂nnte dann ebenfalls nicht √ºber den Chatbot gesteuert werden.

Neben dem technisch-funktionalen Vorgehen stellt man im Laufe der Verwendung vielleicht auch fest, dass man Optimierungen haben m√∂chte. Man kann das Modell ja nicht nur neu trainieren, weil Ger√§te hinzugef√ºgt oder gel√∂scht wurden, sondern man m√∂chte vielleicht andere Eingaben nutzen, m√∂gliche Synonyme usw., weil man ja viele S√§tze nie gleich formuliert. Mit unterschiedlichen S√§tzen m√∂chte man aber am Ende unter Umst√§nde das gleiche Ergebnis erzielen. Wenn man dies entsprechend konfigurieren und trainieren kann, hilft dies, die Anwendung benutzerfreundlicher und individueller f√ºr den/die Anwender zu gestalten.

---

### **Was ist das Ziel?**

* **Verstehen von Benutzeranfragen**: Die KI soll in der Lage sein, einfache Anfragen zu verstehen (z.‚ÄØB. ‚ÄûWie ist die Temperatur im Wohnzimmer?‚Äú oder ‚ÄûSchalte das Licht ein‚Äú).
* **Interaktion mit openHAB**: Die KI muss diese Anfragen verarbeiten und dann die entsprechenden Aktionen in openHAB ausl√∂sen (z.‚ÄØB. den Status von Items abfragen oder Befehle an openHAB senden).

---

### **M√∂glichkeiten der KI-Entwicklung f√ºr diesen Anwendungsfall**

1. **TensorFlow (und Keras)**:
   TensorFlow ist ein sehr m√§chtiges Framework f√ºr maschinelles Lernen und k√∂nnte verwendet werden, um **ein Modell f√ºr Textklassifikation** oder **Intent-Erkennung** zu trainieren. Du k√∂nntest ein Modell erstellen, das Eingaben (z.‚ÄØB. Benutzernachrichten) in bestimmte Kategorien einordnet und dann den entsprechenden Befehl f√ºr openHAB ausgibt.

   **Vorteile**:

   * Flexibilit√§t und Leistung f√ºr komplexe Modelle.
   * Gro√üe Community und viele Ressourcen.

   **Nachteile**:

   * TensorFlow kann relativ komplex sein und erfordert eine gewisse Einarbeitung, besonders bei Textdaten.

2. **Alternativen zu TensorFlow:**
   Hier sind einige andere Frameworks, die sich gut f√ºr Textklassifikation und Intent-Erkennung eignen:

   * **spaCy**: Ein schnelles und einfach zu verwendendes NLP-Framework. Es bietet viele vortrainierte Modelle und kann f√ºr Named Entity Recognition (NER), Textklassifikation und Intent-Erkennung verwendet werden.
   * **Rasa**: Eine End-to-End-NLP- und Dialog-Management-L√∂sung, die speziell f√ºr Chatbots entwickelt wurde. Mit Rasa kannst du ein Modell trainieren, das sowohl **Intents** (z.‚ÄØB. ‚ÄûTemperatur abfragen‚Äú) als auch **Entit√§ten** (z.‚ÄØB. ‚ÄûWohnzimmer‚Äú) erkennt und auf diese reagiert.
   * **Hugging Face Transformers**: Dies ist eine der modernsten NLP-Bibliotheken, die leistungsstarke vortrainierte Modelle wie GPT-3, BERT und T5 enth√§lt. Damit kannst du ein Modell trainieren, das sowohl das Verstehen als auch das Generieren von Text √ºbernimmt.

---

### **Projektplanung und Struktur**

#### 1. **System√ºberblick**

* **Frontend (Flask + HTML/JS)**:

  * Web-Oberfl√§che mit einem Login-System.
  * **Benutzer-Chat**: Normale Benutzer k√∂nnen mit dem Bot interagieren.
  * **Admin-Panel**: Admins k√∂nnen Daten f√ºr das Training hinzuf√ºgen und das Modell neu trainieren.
  * **Datenbank (z.‚ÄØB. SQLite/MySQL)**: Speichern der Trainingsdaten, Chatverl√§ufe, Synonym-Liste, Benutzeraccounts und Modelle.

* **Backend (Flask + Python)**:

  * Flask-Anwendung f√ºr die Kommunikation mit dem Frontend und die Verarbeitung der Anfragen.
  * **Modelltraining**: Das Backend wird in der Lage sein, das Modell basierend auf den eingegebenen Daten zu trainieren.
  * **Modell-API**: Ein API-Endpunkt, der auf Chat-Anfragen reagiert, basierend auf einem trainierten Modell.

* **Modell-Training (TensorFlow / Rasa / spaCy / Hugging Face)**:

  * Das Modell wird auf Basis der hinzugef√ºgten Trainingsdaten **dynamisch** trainiert.

#### 2. **Ben√∂tigte Daten f√ºr das Modell-Training**

Um das Modell zu trainieren, ben√∂tigen wir **beispielhafte Fragen (Intents)** und **Entit√§ten**, die das Modell sp√§ter klassifizieren soll. Diese Daten k√∂nnen durch **manuelles Hinzuf√ºgen** im Admin-Bereich oder durch **automatisches Lernen** aus den Benutzer-Chat-Eingaben generiert werden.

##### Beispiel f√ºr Trainingsdaten (strukturierte Form)

Die **Trainingsdaten** bestehen aus zwei Hauptkomponenten:

* **Intents**: Was der Benutzer zu erreichen versucht (z.‚ÄØB. ‚ÄûTemperatur abfragen‚Äú).
* **Entit√§ten**: Bestimmte Informationen aus der Nachricht (z.‚ÄØB. ‚ÄûWohnzimmer‚Äú als Raumname).

###### Beispiel:

```json
{
    "intents": [
        {
            "intent": "Temperatur_abfragen",
            "examples": [
                "Wie ist die Temperatur im Wohnzimmer?",
                "Was ist die Temperatur im Schlafzimmer?",
                "Wie warm ist es im Wohnzimmer?"
            ],
            "entities": [
                {"entity": "Raum", "value": "Wohnzimmer"},
                {"entity": "Raum", "value": "Schlafzimmer"}
            ]
        },
        {
            "intent": "Licht_steuern",
            "examples": [
                "Schalte das Licht im Flur ein.",
                "Mach das Licht im Wohnzimmer an.",
                "Licht aus im Flur."
            ],
            "entities": [
                {"entity": "Ger√§t", "value": "Flur_Licht"},
                {"entity": "Ger√§t", "value": "Wohnzimmer_Licht"}
            ]
        }
    ]
}
```

##### Erkl√§rungen:

* **Intent**: Die allgemeine Bedeutung der Anfrage (z.‚ÄØB. ‚ÄûTemperatur\_abfragen‚Äú oder ‚ÄûLicht\_steuern‚Äú).
* **Examples**: Beispiele f√ºr Nachrichten, die dem Intent zugeordnet werden.
* **Entities**: Bestimmte Entit√§ten (z.‚ÄØB. ‚ÄûWohnzimmer‚Äú, ‚ÄûFlur\_Licht‚Äú) aus den Beispielen.

Ebenfalls wird deutlich, warum man so etwas wie Synonyme ben√∂tigt. Es kann z.B. hei√üen `Licht ein` oder `Licht an`.

---

#### 3. **Struktur der Anwendung**

* **Flask** verwaltet die Routen f√ºr die Benutzeroberfl√§che, den Chat und das Admin-Panel.
* **Datenbank** (z.‚ÄØB. SQLite oder MySQL): Speichert Benutzeranfragen und Trainingsdaten.

##### **Datenbanktabellen**

* **users**: Speichert Benutzer- und Admin-Daten (f√ºr Login).

  ```sql
  CREATE TABLE users (
      id INT PRIMARY KEY AUTO_INCREMENT,
      username VARCHAR(100),
      password VARCHAR(255),  -- Gespeichert als Hash
      role ENUM('user', 'admin')
  );
  ```

* **chat\_history**: Speichert Chatnachrichten zwischen Benutzern und dem Bot.

  ```sql
  CREATE TABLE chat_history (
      id INT PRIMARY KEY AUTO_INCREMENT,
      user_id INT,
      message TEXT,
      response TEXT,
      timestamp DATETIME,
      FOREIGN KEY (user_id) REFERENCES users(id)
  );
  ```

Rein theoretisch k√∂nnte man mit Reinforcement Learning auch den Chatverlauf f√ºr das Training wiederverwenden.

* **training\_data**: Speichert Trainingsdaten f√ºr das Modell.

  ```sql
  CREATE TABLE training_data (
      id INT PRIMARY KEY AUTO_INCREMENT,
      intent VARCHAR(100),
      example TEXT,
      entity VARCHAR(100),
      value VARCHAR(100)
  );
  ```

F√ºr **Synonyme** muss man nun ein bisschen komplizierter vorgehen. Hier reicht eine einzige Tabelle nicht aus. Man hat eine `n:m`-Beziehung, bedeutet man muss drei Tabellen anlegen.

Um eine Tabelle f√ºr Synonyme in SQL zu erstellen, solltest du eine Datenstruktur w√§hlen, die flexible Beziehungen zwischen W√∂rtern erlaubt ‚Äì insbesondere eine **n\:m-Beziehung** (also viele zu vielen). Denn ein Wort kann mehrere Synonyme haben, und ein Synonym kann wiederum f√ºr mehrere W√∂rter gelten.

L√∂sung: Drei Tabellen

Du kannst drei Tabellen verwenden:

1. **`woerter`** ‚Äì Liste aller W√∂rter.
2. **`synonyme`** ‚Äì Liste aller Synonym-Gruppen oder Paarungen.
3. **`wort_synonym`** ‚Äì Verkn√ºpfungstabelle, die die n\:m-Beziehung abbildet.

Beispielstruktur:

```sql
-- Tabelle f√ºr W√∂rter
CREATE TABLE woerter (
    id SERIAL PRIMARY KEY,
    wort TEXT NOT NULL UNIQUE
);

-- Tabelle f√ºr Synonymgruppen
CREATE TABLE synonymgruppen (
    id SERIAL PRIMARY KEY
);

-- Verkn√ºpfungstabelle zwischen W√∂rter und Synonymgruppen
CREATE TABLE wort_synonym (
    wort_id INT REFERENCES woerter(id),
    synonymgruppe_id INT REFERENCES synonymgruppen(id),
    PRIMARY KEY (wort_id, synonymgruppe_id)
);
```

Beispiel f√ºr die Nutzung:

Wenn du z.‚ÄØB. eine Synonymgruppe f√ºr ‚ÄûAuto‚Äú, ‚ÄûWagen‚Äú und ‚ÄûFahrzeug‚Äú erstellen willst:

```sql
-- W√∂rter einf√ºgen
INSERT INTO woerter (wort) VALUES ('Auto'), ('Wagen'), ('Fahrzeug');

-- Neue Synonymgruppe erstellen
INSERT INTO synonymgruppen DEFAULT VALUES;

-- IDs abfragen
SELECT id FROM synonymgruppen ORDER BY id DESC LIMIT 1; -- z.‚ÄØB. id = 1
SELECT id FROM woerter WHERE wort IN ('Auto', 'Wagen', 'Fahrzeug'); -- z.‚ÄØB. 1,2,3

-- Verkn√ºpfungen herstellen
INSERT INTO wort_synonym (wort_id, synonymgruppe_id) VALUES
(1, 1), (2, 1), (3, 1);
```

Abfragebeispiel: Synonyme f√ºr ‚ÄûAuto‚Äú finden

```sql
SELECT w2.wort
FROM woerter w1
JOIN wort_synonym ws1 ON w1.id = ws1.wort_id
JOIN wort_synonym ws2 ON ws1.synonymgruppe_id = ws2.synonymgruppe_id
JOIN woerter w2 ON ws2.wort_id = w2.id
WHERE w1.wort = 'Auto' AND w2.wort != 'Auto';
```

Alternative: Direkte Paarweise Speicherung (nur bei einfacher Beziehung)

Falls du nur einfache paarweise Synonyme speichern willst (weniger flexibel):

```sql
CREATE TABLE synonyme (
    wort1 TEXT NOT NULL,
    wort2 TEXT NOT NULL,
    PRIMARY KEY (wort1, wort2)
);
```

Das ist allerdings bei gr√∂√üeren Synonymgruppen schwer wartbar und schlecht erweiterbar.

Eventuell ergibt es sogar Sinn, dass man Synonyme nicht in einzelne Worte denkt, sondern vielleicht in ganzen S√§tze oder Teils√§tze.

Wie genau eine Tabelle f√ºr **Modelle** aussieht, h√§ngt letzen Endes sehr stark von dem entwickelten Modell ab. Dies ist dann auch unter Umst√§nden abh√§ngig davon, ob man z. B. spaCy verwendet oder Tensorflow, usw. Vorteile der Speicherung der Modelle hat es, dass man nicht nur zwangsl√§ufig das zuletzt trainierte Modell verwenden kann. Man k√∂nnte z. B. im Benutzerchat eine Funktion anbieten, mit der man zwischen den Modellen wechselt (√§hnlich, wie z. B. bei ChatGPT). Auch k√∂nnen √§ltere Modellversionen m√∂glicherweise auch f√ºr ein Reinforcement Learning verwendet werden. Im Zweifelsfall kann auch eine Datenbanktabelle f√ºr Modelle einfach auch nur als Backup dienen.

Nach einem Training soll das Modell am besten automatisch in eine Datenbank gespeichert werden. Es empfiehlt sich, dass ein Zeitstempel des letzten Trainings gespeichert wird und das es vielleicht ein Feld mit Versionsnummer gibt, welches automatisch iteriert (Das neueste Modell hat immer eine h√∂here Zahl, als das vorherige. Hier empfiehlt es sich `Integer` als Datentyp zu verwenden).

---

#### 4. **Funktionsweise des Admin-Panels**

* **Admin-Panel**:

  * **Daten hinzuf√ºgen**: Admins k√∂nnen neue **Intents** und **Beispiel-Fragen** hinzuf√ºgen (√ºber ein Webformular).
  * **Synonyme hinzuf√ºgen**: Admins k√∂nnen neue **Synonyme** hinzuf√ºgen (√ºber ein Webformular).  
  * **Modell-Training starten**: Ein Button zum Starten des Trainingsprozesses. Nach Klick wird der Backend-Prozess angesto√üen, der die Trainingsdaten nimmt und das Modell trainiert. (Ein neues Modell soll nachdem Training automatisch in die Datenbank gespeichert werden)

  ##### **Beispiel f√ºr ein Admin-Formular**:

  * **Intent**: Auswahl eines vorhandenen Intents oder Eingabe eines neuen Intents.

  * **Beispiel-Fragen**: Textfeld, in das Admins neue Fragen eingeben k√∂nnen, die dem Intent zugeordnet werden.

  * **Entit√§ten**: Eingabefelder f√ºr die Entit√§ten (z.‚ÄØB. Raumnamen oder Ger√§te).

  * **Button ‚ÄûTrainieren‚Äú**: Wenn der Admin auf diesen Button klickt, wird der Trainingsprozess angesto√üen.

Ein Beispiel f√ºr das Speichern der Synonym-Liste lasse ich hier ausnahmsweise weg. Ergibt sich aus den Datenbanktabellen.

---

#### 5. **Automatisiertes Lernen aus Chatnachrichten**

Um das Modell **dynamisch** zu trainieren, k√∂nnen auch **Benutzereingaben** als Trainingsdaten verwendet werden. Dies k√∂nnte so ablaufen:

* **Interaktionen speichern**: Jede Nachricht, die der Benutzer sendet, wird zusammen mit der Antwort des Bots in der **Datenbank** gespeichert.
* **Trainingsdaten generieren**: Ein Admin kann dann alle gespeicherten Benutzernachrichten durchsuchen und entscheiden, ob diese in das Training aufgenommen werden sollen.
* **Verfeinerung**: Nach einer gewissen Anzahl von Interaktionen kann das Modell mit diesen neuen Beispielen neu trainiert werden, um auf h√§ufig gestellte Fragen und neue Anfragen besser zu reagieren.

---

#### 6. **Trainingsprozess**

* **Button ‚ÄûTrainieren‚Äú**: Wenn der Admin den Button klickt, wird das System:

  * Die aktuellen Trainingsdaten aus der Datenbank abrufen.
  * Das Modell (z.‚ÄØB. TensorFlow oder spaCy) mit den neuen Daten trainieren.
  * Die neuen Modellparameter speichern und das aktualisierte Modell im Backend bereitstellen.

Auch hier muss man sich m√∂glicherweise √ºberlegen, ob man die Modellparameter oder das ganze Modell speichert. Vermutlich ergibt sogar beides Sinn. Die Modellparameter k√∂nnen ja √ºber andere Tabellen bereits gespeichert sein und w√ºrden f√ºr ein erneutes Training ja bereits ausreichen.

---

#### 7. **Projektaufbau (Workflow)**

* **Login**: Benutzer und Admins melden sich an.
* **Benutzer-Chat**: Normale Benutzer k√∂nnen mit dem Bot interagieren, ihre Nachrichten werden gespeichert.
* **Admin-Paneel**: Admins k√∂nnen Daten f√ºr das Training hinzuf√ºgen und das Modell trainieren.
* **Training starten**: Admin klickt auf ‚ÄûTrainieren‚Äú, um das Modell mit neuen Daten zu trainieren.
* **Modell verwenden**: Sobald das Modell trainiert ist, wird es f√ºr die Chatbot-Interaktionen verwendet.

---

#### 8. **Dynamisches Lernen im Chat**

Um das Modell kontinuierlich zu verbessern, k√∂nnten Benutzereingaben nach einer **Best√§tigung** durch den Admin ins Training aufgenommen werden. Dies w√§re eine Form des ‚Äû**aktiven Lernens**‚Äú (engl. **active learning**).

#### **Zusammenfassung**:

Das System k√∂nnte folgenderma√üen aufgebaut werden:

1. **Frontend** (Flask + HTML/JS) f√ºr den Chat und Admin-Bereich.
2. **Backend** (Flask + Python) zur Verarbeitung von Nachrichten und Verwaltung des Trainingsprozesses.
3. **Datenbank** zur Speicherung von Benutzerinformationen, Chats und Trainingsdaten.
4. **Modelltraining** √ºber einen Admin-Button, der das Modell mit den neuesten Trainingsdaten aktualisiert.

**Wichtige Schritte f√ºr den Aufbau**:

1. Design und Implementierung der **Datenbankstruktur**.
2. Aufbau der **Flask-Anwendung** f√ºr den Chat und das Admin-Panel.
3. Erstellung der **Trainingslogik** und Integration des **KI-Modells**.
4. Erstellung der **Admin-Oberfl√§che** zur Verwaltung von Trainingsdaten und Training des Modells.

Ich denke dies ist bislang nur ein Vorschlag zum Systementwurf. Der ist relativ pr√§zise. W√§hrend der Bearbeitung entstehen aber m√∂glicherweise andere Anforderungen bzw. man wird feststellen, dass man manche Dinge vielleicht etwas anders strukturieren und entwickeln muss. Dieses Vorgehen soll jedoch erl√§utern, wie man sich das geplante System in etwa vorstellen k√∂nnen soll.

---

### **Ansatz: KI-gest√ºtzter Chatbot mit TensorFlow (oder Alternativen)**

#### 1. **Daten sammeln**:

Um ein Modell zu trainieren, musst du zun√§chst eine Datenbasis aufbauen, die aus **Beispiel-Fragen** und den dazugeh√∂rigen **Befehlen** besteht. Diese Daten k√∂nnten aussehen wie:

```plaintext
Frage: "Wie ist die Temperatur im Wohnzimmer?"
Befehl: "GET:Wohnzimmer_Temperatur"

Frage: "Schalte das Licht im Flur ein."
Befehl: "SET:Flur_Licht:ON"
```

Datenbeispiel f√ºr das Training (Absicht + Entit√§t):

```plaintext
"Wie ist die Temperatur im Wohnzimmer?" -> Intent: "Temperatur_abfragen", Entity: "Wohnzimmer"
"Schalte das Flurlicht ein." -> Intent: "Licht_steuern", Entity: "Flur_Licht", Action: "ON"
```

#### 2. **Modell mit TensorFlow trainieren**:

##### a. **Daten vorbereiten**:

Du kannst den Text in **numerische Features** umwandeln, z.‚ÄØB. mit einem **Tokenizer** oder einer **Word Embedding**-Methode (wie Word2Vec oder GloVe), um ein Modell zu trainieren.

##### b. **Modellarchitektur**:

F√ºr Textklassifikation eignet sich eine **Neural Network Architektur**, die auf **Recurrent Neural Networks (RNNs)** oder **Long Short-Term Memory (LSTM)** basiert. Eine andere M√∂glichkeit ist die Verwendung von **Convolutional Neural Networks (CNNs)**, die ebenfalls bei Textklassifikationen gut funktionieren.

Hier ist ein grundlegendes Beispiel, wie ein **Textklassifikator** in TensorFlow mit **Keras** aussehen k√∂nnte:

##### Beispielcode mit TensorFlow (LSTM):

```python
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

# Beispiel-Daten: Frage-Antwort-Paare
questions = [
    "Wie ist die Temperatur im Wohnzimmer?",
    "Schalte das Licht im Flur ein.",
    "Wie ist die Temperatur im Schlafzimmer?",
    "Schalte das Wohnzimmerlicht aus."
]

labels = [
    "GET:Wohnzimmer_Temperatur",
    "SET:Flur_Licht:ON",
    "GET:Schlafzimmer_Temperatur",
    "SET:Wohnzimmer_Licht:OFF"
]

# Tokenizer initialisieren
tokenizer = Tokenizer()
tokenizer.fit_on_texts(questions)
sequences = tokenizer.texts_to_sequences(questions)
X = pad_sequences(sequences, padding='post')

# Labels in numerische Form umwandeln
label_to_id = {label: idx for idx, label in enumerate(set(labels))}
y = np.array([label_to_id[label] for label in labels])

# Modell erstellen (LSTM)
model = models.Sequential([
    layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=X.shape[1]),
    layers.LSTM(64),
    layers.Dense(32, activation='relu'),
    layers.Dense(len(label_to_id), activation='softmax')
])

# Modell kompilieren und trainieren
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, y, epochs=10, batch_size=2)

# Vorhersage treffen
def predict_intent(message):
    sequence = tokenizer.texts_to_sequences([message])
    padded = pad_sequences(sequence, padding='post', maxlen=X.shape[1])
    pred = model.predict(padded)
    predicted_label = np.argmax(pred)
    return list(label_to_id.keys())[predicted_label]

# Beispiel-Nachricht
message = "Schalte das Licht im Flur ein."
predicted_command = predict_intent(message)
print("Vorhergesagter Befehl:", predicted_command)
```

Bitte beachte, dass dies nur Pseudocode ist, welcher nicht in eine Gesamtstruktur eingebunden ist.

#### 3. **Daten f√ºr Training erweitern**:

Die Qualit√§t des Modells h√§ngt von der Menge und Vielfalt der Trainingsdaten ab. Du kannst die Daten erweitern, indem du mehr Fragen und Antworten hinzuf√ºgst. Hier sind einige Beispiele:

```plaintext
Frage: "Wie ist die Temperatur im Wohnzimmer?"
Frage: "Wie hoch ist die Temperatur im Wohnzimmer?"
Frage: "Wie warm ist es im Wohnzimmer?"

Frage: "Schalte das Licht im Flur aus."
Frage: "Mach das Licht im Flur aus."
Frage: "Flurlicht aus"
```

Du kannst auch **Datenaugmentation** verwenden, um deine Trainingsdaten zu erweitern und das Modell robuster zu machen.

---

#### **Alternativen zu TensorFlow**

Wie bereits erw√§hnt, gibt es auch **andere Tools** wie **Rasa** oder **spaCy**, die sich speziell auf die Entwicklung von Chatbots konzentrieren und dir viele vorgefertigte Modelle und Funktionen bieten, um die Absicht und Entit√§ten zu erkennen.

* **Rasa**:

  * Open-Source-NLP-Framework f√ºr Chatbots.
  * Bietet eine einfache M√∂glichkeit, **Intents** und **Entit√§ten** zu definieren und zu trainieren.
  * Unterst√ºtzt **Sprachdialoge** und kann auch mit openHAB kombiniert werden.
* **spaCy**:

  * Schnelles und modernes NLP-Toolkit.
  * Sehr gut f√ºr Named Entity Recognition (NER) geeignet und k√∂nnte helfen, die verschiedenen Ger√§te und Werte in deinen Fragen zu erkennen.
* **Hugging Face**:

  * Diese Bibliothek ist besonders leistungsf√§hig, wenn du ein **Transformers-Modell** wie BERT oder GPT-2 einsetzen m√∂chtest, um kontextuelle Bedeutung zu verstehen.

---

##### **Zusammenfassung**:

* **TensorFlow** ist eine starke Wahl f√ºr das Trainieren eines **Custom NLP-Modells** zur Intent-Erkennung, ben√∂tigt aber viele Trainingsdaten und Anpassung.
* **spaCy** oder **Rasa** bieten dir einfachere Alternativen f√ºr einen Chatbot, die spezifische Tools f√ºr **Intent-Erkennung und Dialog-Management** bieten.
* **Hugging Face** k√∂nnte eine sehr m√§chtige Option sein, wenn du tiefer in vortrainierte Modelle wie BERT oder GPT einsteigen m√∂chtest.

Wenn du ein **leichtgewichtiges, spezialisiertes Modell** ben√∂tigst, w√ºrde ich dir zu **Rasa** oder **spaCy** raten. Durch Recherche kann man ggf. auch weitere KI-Technologien in Betracht ziehen. Dies gilt hier lediglich nur als Vorschlag.

---

### Exkurs: Wie funktioniert das ohne KI?

Es ist nicht empfohlen auf eine **KI** zu verzichten. Man kann (besser gesagt k√∂nnte) aber den Chatbot so gestalten, dass er auf bestimmte, vordefinierte Fragen oder Befehle reagiert, basierend auf einer **regelbasierten Logik**. Das bedeutet, der Bot erkennt bestimmte Muster in der Benutzereingabe und l√∂st daraufhin entsprechende Aktionen in openHAB aus.

Das w√§re ein einfacherer Ansatz, der keine externe KI ben√∂tigt. Dies bedeutet aber, dass ein Benutzer keine individuellen Abweichungen sich erlauben kann. Es w√ºrde exakt ein einziger vordefinierter Satz geben und sollte dieser erkannt werden, wird entsprechend darauf reagiert. Man kann auch listenbasiert vorgehen, wie z. B., dass in einem Satz vier oder f√ºnf W√∂rter vorkommen muss. Dann w√§re egal, welcher Satz genau eingegeben wurde, sobald diese vier oder f√ºnf W√∂rter vorkommen, wird dann die entsprechende Regel damit getriggert. Wenn man nur eine Liste mit ein oder zwei W√∂rtern hat, kann man die S√§tze nicht gut genug voneinander unterscheiden. Hat man wiederum eine Liste mit zu vielen W√∂rtern, dann ist es ebenfalls denkbar, dass der Benutzer es nicht schafft, einen geeigneten Satz zu formulieren.

Genau dieser Umstand f√ºhrt dazu, dass man mit einer **regelbasierten Logik** nur bis zu einem gewissen Punkt gut arbeiten kann. Je komplexer die Anforderungen des Benutzers sind, desto mehr wird eine **KI** notwendig.

---

#### üõ† Beispiel f√ºr einen **regelbasierten Chatbot** in Python mit Flask

In diesem Beispiel reagiert der Bot auf vordefinierte Fragen wie:

* ‚ÄûWie ist die Temperatur im Wohnzimmer?‚Äú
* ‚ÄûSchalte das Licht im Flur ein.‚Äú

Der Bot nutzt **Python** und **Flask** als Backend, um √ºber die openHAB REST API mit deinem Smart Home zu kommunizieren.

Die S√§tze m√ºssten in diesem Beispiel relativ exakt so formuliert werden, sonst w√ºrde keine Antwort erfolgen.

##### üîß 1. Backend in Flask

```python
from flask import Flask, render_template, request, jsonify
import requests

# === Konfiguration ===
OPENHAB_BASE_URL = 'http://openhab.local:8080/rest'  # openHAB-URL anpassen
TEMPERATURE_ITEM = 'Wohnzimmer_Temperatur'  # openHAB Item f√ºr Temperatur

app = Flask(__name__)

# === openHAB: Status abfragen ===
def get_item_state(item_name):
    try:
        response = requests.get(f"{OPENHAB_BASE_URL}/items/{item_name}/state")
        response.raise_for_status()
        return response.text
    except Exception as e:
        return f"Fehler: {e}"

# === openHAB: Item setzen ===
def set_item_state(item_name, command):
    try:
        response = requests.post(f"{OPENHAB_BASE_URL}/items/{item_name}", data=command,
                                 headers={'Content-Type': 'text/plain'})
        response.raise_for_status()
        return "OK"
    except Exception as e:
        return f"Fehler: {e}"

# === Regelbasierte Logik f√ºr den Chatbot ===
def process_message(user_message):
    user_message = user_message.lower()

    if "temperatur" in user_message and "wohnzimmer" in user_message:
        state = get_item_state(TEMPERATURE_ITEM)
        return f"Die aktuelle Temperatur im Wohnzimmer betr√§gt: {state}¬∞C."

    elif "licht" in user_message and "flur" in user_message and "ein" in user_message:
        result = set_item_state('Flur_Licht', 'ON')
        return f"Das Licht im Flur wurde eingeschaltet. Ergebnis: {result}"

    elif "licht" in user_message and "flur" in user_message and "aus" in user_message:
        result = set_item_state('Flur_Licht', 'OFF')
        return f"Das Licht im Flur wurde ausgeschaltet. Ergebnis: {result}"

    else:
        return "Entschuldigung, das habe ich nicht verstanden. Versuche es mit einer anderen Anfrage."

# === Routen ===
@app.route("/")
def index():
    return render_template("chat.html")

@app.route("/chat", methods=["POST"])
def chat():
    user_message = request.json.get("message", "")
    reply = process_message(user_message)
    return jsonify({"reply": reply})

if __name__ == "__main__":
    app.run(debug=True)
```

Man kann den nachfolgenden Teil k√ºrzen:

```python
elif "licht" in user_message and "flur" in user_message and "aus" in user_message:
```

Dieser k√∂nnte auch wie folgt dann aussehen:

```python
elif ["licht", "flur", "aus"] in user_message:
```

Idealerweise w√ºrde man hier nat√ºrlich auch die Worte aus einer Datenbank auslesen und Regeln √ºber Datenbanken erstellen lassen. Auch eine M√∂glichkeit f√ºr Synonyme w√§re, dass man z. B. `flur` und `Flur` erlaubt. Ebenfalls m√∂glich ist es, dass man alle Worte einheitlich zu klein √§ndert, damit man die Gro√ü-/Kleinschreibung als Fehlerquelle elementiert. Dies kann ja auch mal versehentlich durch Tippfehler bei der Chateingabe entstehen.

In diesem Beispiel ist jetzt die Verarbeitung der Chateingabe statisch. Durch eine Verwendung einer Datenbank, k√∂nnte man diesen Teil dann bereits dynamisch gestalten. Sp√§testens wenn an dieser Stelle eine **KI** angedockt wird, wird man um eine dynamische Verarbeitung nicht drumherum kommen.

In dem gek√ºrzten Teil sieht man, dass auch eine Liste verwendet werden kann. Schaue ich mir den ersten Teilcode an, dann sehe ich eine **UND**-Verkn√ºpfung. Auch so k√∂nnte man sich vorstellen, dass anstelle eines Wortes jedesmal eine Synonym-Liste verwendet wird. Man k√∂nnte ja ein Wort abfragen und eine Liste mit allen Synonymen zur√ºckgeben. Wenn man Listen verwendet, dann kann ich auch eine Liste mit einer anderen Liste erg√§nzen, was ebenfalls eine M√∂glichkeit w√§re, um Synonyme f√ºr eine √úberpr√ºfung einzupflegen.

#### üîß 2. Frontend in HTML (chat.html)

```html
<!DOCTYPE html>
<html>
<head>
  <title>openHAB Chatbot</title>
  <script>
    async function sendMessage() {
      const input = document.getElementById("message");
      const chat = document.getElementById("chat");

      const userText = input.value;
      chat.innerHTML += "<b>Du:</b> " + userText + "<br>";

      const response = await fetch("/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message: userText })
      });

      const data = await response.json();
      chat.innerHTML += "<b>Bot:</b> " + data.reply + "<br><br>";
      input.value = "";
    }
  </script>
</head>
<body>
  <h1>üí¨ openHAB Chatbot</h1>
  <div id="chat" style="border:1px solid #ccc; padding:10px; height:300px; overflow:auto;"></div>
  <input type="text" id="message" placeholder="Nachricht..." onkeydown="if(event.key==='Enter')sendMessage()" />
  <button onclick="sendMessage()">Senden</button>
</body>
</html>
```

Ich empfehle grundlegend, wenn man ein Frontend verwendet, dass man am besten etwas vorgefertigtes nutzt. Es gilt mittlerweile als Standard, dass man das Frontend-Framework [Bootstrap](https://getbootstrap.com/) nutzt. Dann hat man nicht nur schon ein sch√∂nes und vorgefertigtes Desing, sondern kann auch bereits auf einige n√ºtzliche JavaScript-Funktionen zur√ºckgreifen. Dies gibt dem Gestalter auch f√ºr Interaktionen bessere M√∂glichkeiten.

---

#### üîç Was passiert hier?

1. **Flask Backend**:

   * Wenn ein Benutzer eine Nachricht sendet, wird diese vom Server verarbeitet.
   * Der Bot sucht nach bestimmten Schl√ºsselw√∂rtern (z.‚ÄØB. ‚ÄûTemperatur‚Äú, ‚ÄûLicht‚Äú, ‚ÄûFlur‚Äú).
   * Je nach Nachricht ruft der Bot entweder den **Status eines Items** ab oder sendet einen **Befehl an openHAB**, um ein Ger√§t zu steuern.

2. **Frontend (HTML)**:

   * Du hast eine einfache Benutzeroberfl√§che, in der du Nachrichten eingeben kannst.
   * Die Antwort des Bots wird unter der Chatbox angezeigt.

---

#### üí° Erweiterungsm√∂glichkeiten

* **Weitere Ger√§te und Items**: Du kannst den Bot um weitere openHAB-Ger√§te (z.‚ÄØB. Heizungen, Jalousien) erweitern, indem du zus√§tzliche Bedingungen in der `process_message`-Funktion hinzuf√ºgst.
* **Sprachsteuerung**: Du k√∂nntest auch Spracherkennung (z.‚ÄØB. mit der Google Speech-to-Text API) hinzuf√ºgen, um die Nachrichten per Sprache zu senden.
* **Nutzerfreundlichkeit**: Erweiterungen wie die M√∂glichkeit, mehrere Ger√§te zu steuern oder zu kombinieren (z.‚ÄØB. ‚ÄûSchalte das Wohnzimmerlicht und die Heizung an‚Äú).

Weitere Ger√§te und Items lassen sich sehr viel sch√∂ner nat√ºrlich durch eine Datenbank hinzuf√ºgen. Hier dann entsprechend gleich mit ihrer Regel. Die Nutzerfreundlichkeit ist meiner Meinung nach hier nicht ideal. Mit einer Datenbank wird dies sch√∂ner, weil man nicht den Programmcode √§ndern muss, sondern der Benutzer kann das Programm durch eine Weboberfl√§che erweitern.

---

#### Fazit

In diesem Szenario brauchst du keine KI, sondern baust einen **regelbasierten Chatbot**, der auf spezifische Eingaben reagiert. Der Vorteil ist, dass du die volle Kontrolle √ºber die Funktionalit√§ten hast, ohne auf komplexe KI-Systeme angewiesen zu sein. Nachteile sind, dass dies nicht dynamisch ist (eine Datenbank w√ºrde abhilfe schaffen) und man nur eingeschr√§nkte Chateingaben zulassen k√∂nnte.

---



## üß† Zusammenfassung:

* ‚úÖ Trennung von Benutzer-UI und Admin-UI (ggf. kann man ja noch andere Dienste, wie einen Sprachassistenten anbinden).
* ‚úÖ Zentrale API mit klaren Funktionen
* ‚úÖ Zukunftssicher durch Sprachintegration und weitere Clients
* ‚úÖ Bessere Sicherheit, Wartbarkeit und Erweiterbarkeit

# Hintergrundwissen

## Fuzzy Matching

Das **Fuzzy Matching** kann man im deutschen als unscharfe Suche betiteln. Es ist eine Klasse von String-Matching-Algorithmen, mit der man bestimmte Zeichenketten (Strings) in einer l√§ngeren Zeichenkette oder einem Text suchen bzw. finden k√∂nnen sollte.  Es wird daher auch oft als Fuzzy-Suche oder Fuzzy-String-Suche betitelt.

Aus:

[https://www.klippa.com/de/blog/informativ/fuzzy-matching-de/](https://www.klippa.com/de/blog/informativ/fuzzy-matching-de/)

Mit Fuzzy-Matching kann ich darauf reagieren, wenn z. B. nur 80% eines Wortes/Satzes richtig erkannt wurde. Hier mal Beispiele.

```
Gesucht: Bestellnummer

Richtig w√§ren:
Bestellnr.
Bestelnummer
Bestellnumer
Bestellnummmer
...
```

Also m√∂gliche Tippfehler oder auch Abk√ºrzungen sollen ja darufhin deuten, dass ein- und dasselbe Worte gemeint ist. In Zusammenhang mit Synonymen w√ºrde man durch Fuzzy Matching dem Benutzer so extrem viele Eingabem√∂glichkeiten erm√∂glichen. Man formuliert ja nicht nur S√§tze um, man vertippt sich auch mal oder k√ºrzt einzelne W√∂rter ab.

**Fuzzy Matching** nimmt also Korrekturen vor. Dies k√∂nnten im allgemeinen die nachfolgenden sein:

* **Einf√ºgen** ‚Äì Hinzuf√ºgen eines Buchstabens zur Vervollst√§ndigung des Wortes (z. B. `Rechnun` wird zu `Rechnung`)
* **L√∂schen** ‚Äì Entfernen eines Buchstabens aus einem Wort (z. B. `Rechnnung` wird zu `Rechnung`)
* **Substitution** ‚Äì Vertauschen eines Buchstabens, um ein Wort zu korrigieren (z. B. `Technung` wird zu `Rechnung`)
* **Transposition** ‚Äì Vertauschen von Buchstaben, um ein Wort zu korrigieren (z. B. `Rehcnung` wird zu `Rechnung`)

Jeder Korrektur, die durchgef√ºhrt werden muss, wird eine ‚ÄûBearbeitungsdistanz‚Äú von 1 zugeschrieben. Die Bearbeitungsdistanzen beeinflussen die oben erw√§hnte Trefferquote. Wenn Sie beispielsweise eine Zeichenfolge mit 11 Zeichen haben und 2 Korrekturen vornehmen m√ºssen, betr√§gt die endg√ºltige Trefferquote **81,81 %**.

```
Berechnung: 100%- 2 / 11= 81.81%  
```

Neben diesen Korrekturen kann **Fuzzy Matching** auch verwendet werden, um Zeichensetzungen, zus√§tzliche W√∂rter und fehlende Leerzeichen in Zeichenketten oder Texten zu korrigieren.

### Fuzzy-Matching-Algorithmen

Fuzzy Matching f√§llt in die Kategorie der Methoden, f√ºr die es keinen spezifischen Algorithmus gibt, der alle Szenarien und Anwendungsf√§lle abdeckt. Daher werden wir einige der am h√§ufigsten verwendeten und zuverl√§ssigsten Fuzzy-Matching-Algorithmen f√ºr die Suche nach ungef√§hren Daten√ºbereinstimmungen behandeln:

* Levenshtein-Distanz (LD)
* Hamming-Distanz (HD)
* Damerau-Levenshtein

#### Levenshtein-Distanz

Die **Levenshtein-Distanz (LD)** ist eine Fuzzy-Matching-Technik, die zwei Zeichenfolgen beim Vergleich und der Suche nach einer √úbereinstimmung ber√ºcksichtigt. Je h√∂her der Wert der Levenshtein-Distanz ist, desto weiter sind die beiden Zeichenfolgen oder ‚ÄûBegriffe‚Äú von einer identischen √úbereinstimmung entfernt.

Wie erhalten wir nun den Wert der Levenshtein-Distanz? Die LD zwischen den beiden Zeichenfolgen entspricht der Anzahl der √Ñnderungen, die erforderlich sind, um eine Zeichenfolge in die andere umzuwandeln. F√ºr die LD gelten das Einf√ºgen, L√∂schen und Ersetzen eines einzelnen Zeichens als Bearbeitungsoperationen.

Nehmen wir an, Sie m√∂chten die LD zwischen ‚ÄûRechnungsnummer‚Äú und ‚ÄûRechnungs-Nr.‚Äú messen. Der Abstand zwischen den beiden Begriffen ist ‚Äû1 x u‚Äú, ‚Äû2 x m‚Äú und ‚Äû1 x e‚Äú, was einem Abstand von 4 entsprechen w√ºrde. Warum? Weil Sie diese Zeichen hinzuf√ºgen m√ºssten, um eine √úbereinstimmung zu erreichen. Siehe die Beispiele unten.

##### Levenshtein-Abstand Beispiel

> **Rechnungnummer** ‚Üí Rechnung**s**nummer (Einf√ºgung von ‚Äû**s**‚Äú) ‚Äì Abstand: 1  
> **Rechnung numr** ‚Üí Rechnungsnu**m**m**e**r (Einf√ºgung von ‚Äû**m**‚Äú & ‚Äû**e**‚Äú) ‚Äì Abstand: 2  
> **Rechnung nr** ‚Üí Rechnungsn**u****m****m****e**r (Einf√ºgung von ‚Äû**u, m, m, e**‚Äú) ‚Äì Abstand: 4


#### Hamming-Distanz

Die **Hamming-Distanz (HD)** unterscheidet sich nicht allzu sehr von der Levenshtein-Distanz. Die Hamming-Distanz wird h√§ufig verwendet, um den Abstand zwischen zwei gleich langen Textabschnitten zu berechnen.

Die HD-Methode basiert auf der **ASCII**-Tabelle (American Standard Code for Information Interchange). Zur Berechnung des Abstandswertes verwendet der Hamming-Distanz-Algorithmus die Tabelle, um den Bin√§rcode zu bestimmen, der jedem Buchstaben in den Zeichenketten zugeordnet ist.

##### Hamming-Abstand-Beispiel

Nehmen wir die folgenden Textzeichenfolgen ‚ÄûNumber‚Äú und ‚ÄûLumber‚Äú als Beispiel. Wenn wir versuchen, den HD zwischen den Zeichenfolgen zu bestimmen, ist der Abstand nicht 1, wie es mit dem Levenshtein-Algorithmus der Fall w√§re. Stattdessen w√ºrde er 10 betragen. Das liegt daran, dass die ASCII-Tabelle einen Bin√§rcode von **(1001110)** f√ºr den Buchstaben **N** und **(1001100)** f√ºr den Buchstaben **L** anzeigt.

Beispielrechnung:

> **D** = N ‚Äì L = 1001110 ‚Äì 1001100 = **10**


#### Damerau-Levenshtein

Das Damerau-Levenshtein-Verfahren misst auch den Abstand zwischen zwei W√∂rtern, indem es die erforderlichen √Ñnderungen misst, die vorgenommen werden m√ºssen, um ein Wort an das andere anzupassen. Diese √Ñnderungen h√§ngen von der Anzahl der Operationen ab, wie z. B. Einf√ºgung, L√∂schung oder Ersetzung eines einzelnen Zeichens oder Transposition zweier benachbarter Zeichen.

Hier unterscheidet sich die Damerau-Levenshtein-Distanz von der regul√§ren Levenshtein-Distanz, da sie zus√§tzlich zu den Einzelzeichen-Editieroperationen, auch Transpositionen ber√ºcksichtigt, um eine ungef√§hre √úbereinstimmung zu finden (Fuzzy Match).

##### Damerau-Levenshtein Beispiel

> **Zeichenfolge 1:** Re<strong>ch</strong>nun<strong>g</strong>  
> **Zeichenfolge 2:** Re<strong>hc</strong>nun  
>   
> **Operation 1:** Transposition ‚Üí Vertauschen der Zeichen ‚Äû**h**‚Äú und ‚Äû**c**‚Äú  
> **Operation 2:** Einf√ºgen eines ‚Äû**g**‚Äú am Ende der Zeichenfolge 2


Da zwei Operationen erforderlich waren, um die beiden W√∂rter identisch zu gestalten, **betr√§gt der Abstand 2**. Vereinfacht ausgedr√ºckt z√§hlt jede Operation wie Einf√ºgung, L√∂schung, Transposition usw. als ein Abstand von ‚Äû1‚Äú. Mit der Levenshtein-Distanz m√ºssten Sie jedoch drei Korrekturen vornehmen, was einem Abstand von 3 entspricht.

Alle oben genannten Fuzzy-Matching-Algorithmen unterscheiden sich nat√ºrlich in der Art und Weise, wie die Bearbeitungsdistanz berechnet wird. Dies ist der Grund, warum es keinen FM-Algorithmus gibt, der f√ºr alle geeignet ist. Von den drei vorgestellten Algorithmen ist die Levenshtein-Distanz jedoch der am h√§ufigsten verwendete FM-Algorithmus in der Datenverwaltung und Datenwissenschaft.

Empfehlung: In Python kann man die [fuzzywuzzy-Bibliothek](https://github.com/seatgeek/fuzzywuzzy) testen oder einen eigenen Algorithmus implementieren.

## Intent, Entity, Confidence Score

Aus:

[https://www.melibo.de/blog/was-sind-intent-und-entity](https://www.melibo.de/blog/was-sind-intent-und-entity)

### Intent

Intents, zu Deutsch ‚ÄûAbsichten‚Äú, sind Zwecke oder Ziele, die in den Eingaben eines Kunden zum Ausdruck kommen, um z.B. eine Frage zu einer Retoure zu stellen. Durch die Erkennung der Absicht, die sich in der Kundeneingabe ausdr√ºckt, versucht der KI-Chatbot den richtigen Dialog zu finden und die passende Ausgabe zu w√§hlen. Daf√ºr nutzen KI-Chatbots maschinelles Lernen, um in nat√ºrlicher Sprache die vorher definierte Absicht (Intent) zu erkennen. [1] Einfach gesagt, Intents sind Fragen der User:innen, die dem Chatbot zu einem speziellen Thema gestellt werden und der Versuch des KI-Chatbots, die passende Antwort zu erkennen, um das Problem zu l√∂sen bzw. die Frage zu beantworten.

#### Wie funktionieren Intents?

Bestehende Anbieter wie unter anderem der IBM Watson Assistant [1], Rasa [2] oder Microsoft LUIS [3] basieren alle meist auf dem Prinzip der Intent-Ausgabe. Bevor der Chatbot Intents erkennen kann, m√ºssen erst mal alle Absichten der User:innen definiert werden. Hierf√ºr ist es wichtig, dass man seine Kundenanfragen erst mal identifiziert und seinen Use-Case richtig versteht. Nachdem der Intent-Katalog erstellt und der Bot online genommen wurde, werden die User:innen dem Chatbot Fragen stellen. Jede Anfrage der User:innen durchl√§uft das sogenannte Intent-Matching, also der Zuordnung der Anfrage aus den gesamten Inhalten des Chatbots. Dabei wird anhand von NLP (Natural Language Processing) ein Confidence-Score berechnet, um anhand von Wahrscheinlichkeiten die passende Antwort auszugeben.

### Confidence-Score

Ein kurzer Exkurs zum Thema Confidence-Scores. Die Confidence-Scores liegen zwischen 0 und 1 und geben an, zu wie viel Prozent der Chatbot ein Intent erkannt hat. Zu jeder gestellten Frage der User:innen berechnet der Chatbot also einen Confidence-Score und versucht auf dieser Grundlage, durch Wahrscheinlichkeiten, die richtige Antwort an die User:innen auszugeben. Die Confidence-Scores sind meistens voreingestellt und liegen zwischen 0,6 und 0,7. Das hei√üt, dass der Chatbot Antworten nur dann ausgibt, wenn die Erkennungswahrscheinlichkeit bei mindestens 60 % liegt. Nehmen wir nun als Beispiel an, dass User:innen die Frage stellen ‚ÄûWas kannst du so?‚Äú, um zu erfahren, welche Themen der Chatbot √ºberhaupt beantworten kann. Der KI-Chatbot erkennt zu 89 % Prozent den Intent ‚ÄûWas kannst du?‚Äú. In diesem Beispiel gibt der Chatbot die passende Antwort aus und beantwortet somit die Frage.

#### Bestandteile eines Intents

Ein Intent besteht also aus dem: Intentnamen, dem User-Input, dem Confidence-Score und einer Antwort. Abh√§ngig von der genutzten Technologie k√∂nnen noch weitere Bestandteile dazu kommen, wie Variablen, Actions und Entities.

Ein Beispiel f√ºr Intents

(1) User-Input: Frage eines Users

üôé‚Äç‚ôÇÔ∏è: ‚ÄûVorteile eines Chatbots‚Äú
üôé‚Äç‚ôÇÔ∏è: ‚ÄûWas k√∂nnen Chatbots besonders gut?‚Äú
üôé‚Äç‚ôÇÔ∏è: ‚ÄûWarum sollte ich einen Chatbot holen?‚Äú

(2) Confidence-Score und (3) Intentnamen ‚ÄûVorteile Chatbot‚Äú: Berechnung der Wahrscheinlichkeit anhand vom User-Input

üßÆ : 100 % Erkennung des Intents ‚ÄûVorteile Chatbot‚Äú

(4) Antwort des Chatbots auf die Frage ‚ÄûVorteile Chatbots‚Äú

ü§ñ : Zu den Vorteilen von Chatbots geh√∂ren unter anderem und abh√§ngig von der Branche: Automatisierung von Prozessen, wodurch Fehler beim Support reduziert sowie Zeit und Geld eingespart werden k√∂nnen. Verk√ºrzte Wartezeiten f√ºr den Kunden. 24/7 Kundensupport. Effizientere Strukturen. Weniger manueller Aufwand f√ºr dich.

### Entity

Im Unterschied zu Intents dienen Entitys oder auch Entities dazu, Informationen der User:innen aus der nat√ºrlichen Sprache zu extrahieren. Jedes Entity verf√ºgt √ºber eine Reihe von Eigenschaften, die mit ihr verbunden sind. Dabei kannst du auf Informationen deines Entities zugreifen. Wie bei einem Intent gibt der Chatbot an, wie hoch der Confidence-Score liegt. Im Unterschied zu Intents liegt der Confidence-Score, aber bei 0 oder 1. Unabh√§ngig davon, ob und wie die Erkennung des Entitys eingestellt ist, haben sogenannte System-Entites immer eine Erkennung von 1. Jedes Entity besitzt einen Wert, einen sogenannten Entit√§tswert. Bei der Erstellung von Entities ist es notwendig, dass neben dem Wert auch Typen definiert werden. Unter Typen versteht man allgemein Synonyme, also W√∂rter, die sich ebenfalls auf dasselbe Vorhaben beziehen, es nur anders umschreiben. Je mehr Synonyme ein Entity hat, desto besser die Erkennung des Chatbots [4].

Grunds√§tzlich unterscheiden wir zwischen System-Entities und Customize-Entities. Die System-Entites sind voreingestellt, das hei√üt im System bereits enthalten. Darunter fallen etwa Zahlen, Uhrzeiten oder Adressen. Diese Entities sind besonders beliebt und wurden in der Vergangenheit besonders h√§ufig verwendet. Die Customize-Entities dagegen sind selbst definierte Werte, die auf den jeweiligen Use-Case angepasst werden.

#### Ein Beispiel f√ºr Entities in der Praxis

üôé‚Äç‚ôÇÔ∏è: ‚ÄûWann kommt mein Produkt Chatbot-Experte in der Landstra√üe 5 an?‚Äú

#### Entities in diesem Beispiel:

Produkt Chatbot Experte (Customize-Entity product_type)
Landstra√üe 5 (Sytem-Entity street_adress)

#### Vorteile von Entites:

Mit Entities kann man User:innen durch Chat Flows in Form von Buttons navigieren, schnell Synonyme definieren und mehrere Anfragen auf einmal verarbeiten. Die System-Entitys helfen au√üerdem dabei, die beliebten Anfragen zum Thema Ort, Zeit und Adresse abzufangen.

[1]: https://cloud.ibm.com/docs/assistant?topic=assistant-intents
[2]: https://rasa.com/open-source/
[3]: https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-utterance
[4]: https://cloud.ibm.com/docs/assistant?topic=assistant-expression-language
